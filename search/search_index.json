{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the MiADE Documentation","text":"<p>MiADE (Medical information AI Data Extractor) is a set of tools for extracting formattable data from clinical notes stored in electronic health record systems (EHRs). Powered by Cogstack's MedCAT.</p>"},{"location":"#installing","title":"Installing","text":"<pre><code>pip install miade\n</code></pre> <p>You may also need to download these additional models to run MiADE:</p> <p>spaCy <pre><code>python -m spacy download en_core_web_md\n</code></pre> med7 <pre><code>pip install https://huggingface.co/kormilitzin/en_core_med7_lg/resolve/main/en_core_med7_lg-any-py3-none-any.whl\n</code></pre></p>"},{"location":"#license","title":"License","text":"<p>MiADE is licensed under Elastic License 2.0.</p> <p>The Elastic License 2.0 is a flexible license that allows you to use, copy, distribute, make available, and prepare derivative works of the software, as long as you do not provide the software to others as a managed service or include it in a free software directory. For the full license text, see our license page.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contribute to MiADE! Contribution guide</p>"},{"location":"about/overview/","title":"Project Overview","text":""},{"location":"about/overview/#background","title":"Background","text":"<p>Data about people\u2019s health stored in electronic health records (EHRs) can play an important role in improving the quality of patient care. Much of the information in EHRs is recorded in ordinary language without any restriction on format ('free text'), as this is the natural way in which people communicate. However, if this information were stored in a standardised, structured format, computers will also be able to process the information to help clinicians find and interpret information for better and safer decision making. This would enable EHR systems such as Epic, the system in place at UCLH since April 2019,  to support clinical decision making. For instance, the system may be able to ensure that a patient is not prescribed medicine that would give them an allergic reaction.</p>"},{"location":"about/overview/#the-challenge","title":"The challenge","text":"<p>Free text may contain words and abbreviations which may be interpreted in more than one way, such as 'HR', which can mean 'Hour' or 'Heart Rate'. Free text may also contain negations; for example, a  diagnosis may be mentioned in the text but the rest of the sentence might say that it was ruled out. Although computers can be used to interpret free text, they cannot always get it right, so clinicians will always have to check the results to ensure patient safety. Expressing information in a  structured way can avoid this problem, but has a big disadvantage - it can be time-consuming for clinicians to enter the information. This can mean that information is incomplete, or clinicians are so busy on the computer that they do not have time to listen to their patients.</p>"},{"location":"about/overview/#meeting-the-need","title":"Meeting the need","text":"<p>The aim of MiADE is to develop a system to support automatic conversion of the clinician\u2019s free text into a structured format. The clinician can check the structured data immediately, before making it a formal part of the patient\u2019s record. The system will record a patient\u2019s diagnoses, medications and allergies in a structured way, using NHS-endorsed clinical data standards (e.g. FIHR and SNOMED CT). It will use a technique called Natural Language Processing (NLP). NLP has been used by research teams to extract information from existing EHRs but has rarely been used to improve the way information is entered in the first place. Our NLP system will continuously learn and improve as more text is analysed and checked by clinicians.</p> <p>We will first test the system in University College London Hospitals, where a new EHR system called Epic is in place. We will study how effective it is, and how clinicians and patients find it when it is used in consultations. Based on feedback, we will make improvements and install it for testing at a second site (Great Ormond Street Hospital). Our aim is for the system to be eventually rolled out to more hospitals and doctors\u2019 surgeries across the NHS.</p>"},{"location":"about/team/","title":"Team","text":"<p>The MiADE project is developed by a team of clinicians, developers, AI researchers, and data standard experts at University College London (UCL) and the University College London Hospitals (UCLH), in collaboration with the Cogstack at King's College London (KCL).</p>"},{"location":"api-reference/annotator/","title":"Annotator","text":"<p>               Bases: <code>ABC</code></p> <p>An abstract base class for annotators.</p> <p>Annotators are responsible for processing medical notes and extracting relevant concepts from them.</p> <p>Attributes:</p> Name Type Description <code>cat</code> <code>CAT</code> <p>The MedCAT instance used for concept extraction.</p> <code>config</code> <code>AnnotatorConfig</code> <p>The configuration for the annotator.</p> Source code in <code>miade/annotators.py</code> <pre><code>class Annotator(ABC):\n    \"\"\"\n    An abstract base class for annotators.\n\n    Annotators are responsible for processing medical notes and extracting relevant concepts from them.\n\n    Attributes:\n        cat (CAT): The MedCAT instance used for concept extraction.\n        config (AnnotatorConfig): The configuration for the annotator.\n    \"\"\"\n\n    def __init__(self, cat: CAT, config: AnnotatorConfig = None):\n        self.cat = cat\n        self.config = config if config is not None else AnnotatorConfig()\n\n        if self.config.negation_detection == \"negex\":\n            self._add_negex_pipeline()\n\n        self._set_lookup_data_path()\n        self._load_paragraph_regex()\n\n        # TODO make paragraph processing params configurable\n        self.structured_prob_lists = {\n            ParagraphType.prob: Relevance.PRESENT,\n            ParagraphType.imp: Relevance.PRESENT,\n            ParagraphType.pmh: Relevance.HISTORIC,\n        }\n        self.structured_med_lists = {\n            ParagraphType.med: SubstanceCategory.TAKING,\n            ParagraphType.allergy: SubstanceCategory.ADVERSE_REACTION,\n        }\n        self.irrelevant_paragraphs = [ParagraphType.ddx, ParagraphType.exam, ParagraphType.plan]\n\n    def _add_negex_pipeline(self) -&gt; None:\n        \"\"\"\n        Adds the negex pipeline to the MedCAT instance.\n        \"\"\"\n        self.cat.pipe.spacy_nlp.add_pipe(\"sentencizer\")\n        self.cat.pipe.spacy_nlp.enable_pipe(\"sentencizer\")\n        self.cat.pipe.spacy_nlp.add_pipe(\"negex\")\n\n    def _set_lookup_data_path(self) -&gt; None:\n        \"\"\"\n        Sets the lookup data path based on the configuration.\n\n        If the `lookup_data_path` is not specified in the configuration, the default path \"./data/\" is used\n        and `use_package_data` is set to True. Otherwise, the specified `lookup_data_path` is used and\n        `use_package_data` is set to False.\n\n        Raises:\n            RuntimeError: If the specified `lookup_data_path` does not exist.\n        \"\"\"\n        if self.config.lookup_data_path is None:\n            self.lookup_data_path = \"./data/\"\n            self.use_package_data = True\n            log.info(\"Loading preconfigured lookup data\")\n        else:\n            self.lookup_data_path = self.config.lookup_data_path\n            self.use_package_data = False\n            log.info(f\"Loading lookup data from {self.lookup_data_path}\")\n            if not os.path.isdir(self.lookup_data_path):\n                raise RuntimeError(f\"No lookup data configured: {self.lookup_data_path} does not exist!\")\n\n    def _load_paragraph_regex(self) -&gt; None:\n        \"\"\"\n        Loads the paragraph regex mappings from a CSV file and initializes the paragraph_regex attribute.\n\n        This method loads the paragraph regex mappings from a CSV file located the lookup data path specified in config.\n        If unspecified, loads the default packaged regex lookup for paragraph headings.\n\n        Returns:\n            None\n        \"\"\"\n        data = load_lookup_data(\n            self.lookup_data_path + \"regex_para_chunk.csv\", is_package_data=self.use_package_data, as_dict=True\n        )\n        self.paragraph_regex = load_regex_paragraph_mappings(data)\n\n    @property\n    @abstractmethod\n    def concept_types(self):\n        \"\"\"\n        Abstract property that should return a list of concept types supported by the annotator.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def pipeline(self):\n        \"\"\"\n        Abstract property that should return a list of pipeline steps for the annotator.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def postprocess(self):\n        \"\"\"\n        Abstract method that should implement the logic for post-processing extracted concepts.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def run_pipeline(self):\n        \"\"\"\n        Abstract method that runs the annotation pipeline on a given note and returns the extracted concepts.\n        \"\"\"\n        pass\n\n    def get_concepts(self, note: Note) -&gt; List[Concept]:\n        \"\"\"\n        Extracts concepts from a note using the MedCAT instance.\n\n        Args:\n            note (Note): The input note to extract concepts from.\n\n        Returns:\n            The extracted concepts from the note.\n        \"\"\"\n        concepts: List[Concept] = []\n        for entity in self.cat.get_entities(note)[\"entities\"].values():\n            try:\n                concepts.append(Concept.from_entity(entity))\n                log.debug(f\"Detected concept ({concepts[-1].id} | {concepts[-1].name})\")\n            except ValueError as e:\n                log.warning(f\"Concept skipped: {e}\")\n\n        return concepts\n\n    def preprocess(self, note: Note, refine: bool = True) -&gt; Note:\n        \"\"\"\n        Preprocesses a note by cleaning its text and splitting it into paragraphs.\n\n        Args:\n            note (Note): The input note to preprocess.\n            refine (bool): Whether to refine the paragraph detection algorithm and allow merging of continuous prose\n            paragraphs, merging to paragraphs with empty bodies with the next prose paragraphs. Default True.\n\n        Returns:\n            The preprocessed note.\n        \"\"\"\n        note.process(self.paragraph_regex, refine=refine)\n\n        return note\n\n    @staticmethod\n    def filter_concepts_in_numbered_list(concepts: List[Concept], note: Note) -&gt; List[Concept]:\n        \"\"\"\n        Filters and returns a list of concepts in a numbered list in a note using a two-pointer algorithm.\n\n        This filters out concepts that may not be relevant given a note that has structured list headings\n        and numbered lists within that. i.e. only return the first line of a numbered list. e.g.\n            1. CCF -\n            - had echo on 15/6\n            - on diuretics\n        will only return the concept CCF as it is the first item in a numbered list\n\n        Args:\n            concepts (List[Concept]): The list of concepts to filter.\n            note (Note): The note containing numbered lists.\n\n        Returns:\n           The filtered list of concepts.\n        \"\"\"\n        # Check there is a numbered list\n        if len(note.numbered_lists) == 0:\n            return concepts\n\n        # Get the global list ranges of all numbered lists in a note\n        global_list_ranges = [\n            (numbered_list.list_start, numbered_list.list_end) for numbered_list in note.numbered_lists\n        ]\n\n        # Flatten the list items from all numbered lists into a single list and sort them\n        list_items = [item for numbered_list in note.numbered_lists for item in numbered_list.items]\n        list_items.sort(key=lambda x: x.start)\n\n        # Sort the concepts by their start index\n        concepts.sort(key=lambda x: x.start)\n\n        filtered_concepts = []\n        concept_idx, item_idx = 0, 0\n\n        # Iterate through concepts and list items simultaneously\n        while concept_idx &lt; len(concepts) and item_idx &lt; len(list_items):\n            concept = concepts[concept_idx]\n            item = list_items[item_idx]\n\n            # Check if the concept is within the global range of any list\n            if any(start &lt;= concept.start &lt; end for start, end in global_list_ranges):\n                # Check for partial or full overlap between concept and list item\n                if (\n                    concept.start &gt;= item.start and concept.end &lt;= item.end\n                ):  # or (concept.start &lt; item.end and concept.end &gt; item.start)\n                    # Concept overlaps with or is within the current list item\n                    filtered_concepts.append(concept)\n                    concept_idx += 1  # Move to the next concept\n                elif concept.end &lt;= item.start:\n                    # If the concept ends before the item starts, move to the next concept\n                    concept_idx += 1\n                else:\n                    # Otherwise, move to the next list item\n                    item_idx += 1\n            else:\n                # If concept is not within a numbered list range, skip and return it\n                filtered_concepts.append(concept)\n                concept_idx += 1\n\n        # After iterating, check if there are remaining concepts after the last list item that might not have been added\n        while concept_idx &lt; len(concepts):\n            concept = concepts[concept_idx]\n            if concept.start &gt;= global_list_ranges[-1][1]:\n                filtered_concepts.append(concept)\n            concept_idx += 1\n\n        return filtered_concepts\n\n    @staticmethod\n    def deduplicate(concepts: List[Concept], record_concepts: Optional[List[Concept]] = None) -&gt; List[Concept]:\n        \"\"\"\n        Removes duplicate concepts from the extracted concepts list by strict ID matching.\n\n        Args:\n            concepts (List[Concept]): The list of extracted concepts.\n            record_concepts (Optional[List[Concept]]): The list of concepts from existing EHR records.\n\n        Returns:\n            The deduplicated list of concepts.\n        \"\"\"\n        if record_concepts is not None:\n            record_ids = {record_concept.id for record_concept in record_concepts}\n            record_names = {record_concept.name for record_concept in record_concepts}\n        else:\n            record_ids = set()\n            record_names = set()\n\n        # Use an OrderedDict to keep track of ids as it preservers original MedCAT order (the order it appears in text)\n        filtered_concepts: List[Concept] = []\n        existing_concepts = OrderedDict()\n\n        # Filter concepts that are in record or exist in concept list\n        for concept in concepts:\n            if concept.id is not None and (concept.id in record_ids or concept.id in existing_concepts):\n                log.debug(f\"Removed concept ({concept.id} | {concept.name}): concept id exists in record\")\n            # check name match for null ids - VTM deduplication\n            elif concept.id is None and (concept.name in record_names or concept.name in existing_concepts.values()):\n                log.debug(f\"Removed concept ({concept.id} | {concept.name}): concept name exists in record\")\n            else:\n                filtered_concepts.append(concept)\n                existing_concepts[concept.id] = concept.name\n\n        return filtered_concepts\n\n    @staticmethod\n    def add_dosages_to_concepts(\n        dosage_extractor: DosageExtractor, concepts: List[Concept], note: Note\n    ) -&gt; List[Concept]:\n        \"\"\"\n        Gets dosages for medication concepts\n\n        Args:\n            dosage_extractor (DosageExtractor): The dosage extractor object\n            concepts (List[Concept]): List of concepts extracted\n            note (Note): The input note\n\n        Returns:\n            List of concepts with dosages for medication concepts\n        \"\"\"\n\n        for ind, concept in enumerate(concepts):\n            next_med_concept = concepts[ind + 1] if len(concepts) &gt; ind + 1 else None\n            dosage_string = get_dosage_string(concept, next_med_concept, note.text)\n            if len(dosage_string.split()) &gt; 2:\n                concept.dosage = dosage_extractor(dosage_string)\n                concept.category = Category.MEDICATION if concept.dosage is not None else None\n                if concept.dosage is not None:\n                    log.debug(\n                        f\"Extracted dosage for medication concept \"\n                        f\"({concept.id} | {concept.name}): {concept.dosage.text} {concept.dosage.dose}\"\n                    )\n\n        return concepts\n\n    @staticmethod\n    def add_numbering_to_name(concepts: List[Concept]) -&gt; List[Concept]:\n        \"\"\"\n        Adds numbering to the names of problem concepts to control output ordering.\n\n        Args:\n            concepts (List[Concept]): The list of concepts to add numbering to.\n\n        Returns:\n            The list of concepts with numbering added to their names.\n        \"\"\"\n        # Prepend numbering to problem concepts e.g. 01 asthma, 02 stroke...\n        for i, concept in enumerate(concepts):\n            concept.name = f\"{(i + 1):02} {concept.name}\"\n\n        return concepts\n\n    def __call__(\n        self,\n        note: Note,\n        record_concepts: Optional[List[Concept]] = None,\n        dosage_extractor: Optional[DosageExtractor] = None,\n    ) -&gt; List[Concept]:\n        \"\"\"\n        Runs the annotation pipeline on a given note and returns the extracted concepts.\n\n        Args:\n            note (Note): The input note to process.\n            record_concepts (Optional[List[Concept]]): The list of concepts from existing EHR records.\n            dosage_extractor (Optional[DosageExtractor]): The dosage extractor to use for extracting dosage information.\n\n        Returns:\n            List[Concept]: The extracted concepts from the note.\n        \"\"\"\n        if dosage_extractor is not None:\n            concepts = self.run_pipeline(note, record_concepts, dosage_extractor)\n        else:\n            concepts = self.run_pipeline(note, record_concepts)\n\n        if self.config.add_numbering:\n            concepts = self.add_numbering_to_name(concepts)\n\n        return concepts\n</code></pre>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.concept_types","title":"<code>concept_types</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Abstract property that should return a list of concept types supported by the annotator.</p>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.pipeline","title":"<code>pipeline</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Abstract property that should return a list of pipeline steps for the annotator.</p>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.__call__","title":"<code>__call__(note, record_concepts=None, dosage_extractor=None)</code>","text":"<p>Runs the annotation pipeline on a given note and returns the extracted concepts.</p> <p>Parameters:</p> Name Type Description Default <code>note</code> <code>Note</code> <p>The input note to process.</p> required <code>record_concepts</code> <code>Optional[List[Concept]]</code> <p>The list of concepts from existing EHR records.</p> <code>None</code> <code>dosage_extractor</code> <code>Optional[DosageExtractor]</code> <p>The dosage extractor to use for extracting dosage information.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Concept]</code> <p>List[Concept]: The extracted concepts from the note.</p> Source code in <code>miade/annotators.py</code> <pre><code>def __call__(\n    self,\n    note: Note,\n    record_concepts: Optional[List[Concept]] = None,\n    dosage_extractor: Optional[DosageExtractor] = None,\n) -&gt; List[Concept]:\n    \"\"\"\n    Runs the annotation pipeline on a given note and returns the extracted concepts.\n\n    Args:\n        note (Note): The input note to process.\n        record_concepts (Optional[List[Concept]]): The list of concepts from existing EHR records.\n        dosage_extractor (Optional[DosageExtractor]): The dosage extractor to use for extracting dosage information.\n\n    Returns:\n        List[Concept]: The extracted concepts from the note.\n    \"\"\"\n    if dosage_extractor is not None:\n        concepts = self.run_pipeline(note, record_concepts, dosage_extractor)\n    else:\n        concepts = self.run_pipeline(note, record_concepts)\n\n    if self.config.add_numbering:\n        concepts = self.add_numbering_to_name(concepts)\n\n    return concepts\n</code></pre>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.add_dosages_to_concepts","title":"<code>add_dosages_to_concepts(dosage_extractor, concepts, note)</code>  <code>staticmethod</code>","text":"<p>Gets dosages for medication concepts</p> <p>Parameters:</p> Name Type Description Default <code>dosage_extractor</code> <code>DosageExtractor</code> <p>The dosage extractor object</p> required <code>concepts</code> <code>List[Concept]</code> <p>List of concepts extracted</p> required <code>note</code> <code>Note</code> <p>The input note</p> required <p>Returns:</p> Type Description <code>List[Concept]</code> <p>List of concepts with dosages for medication concepts</p> Source code in <code>miade/annotators.py</code> <pre><code>@staticmethod\ndef add_dosages_to_concepts(\n    dosage_extractor: DosageExtractor, concepts: List[Concept], note: Note\n) -&gt; List[Concept]:\n    \"\"\"\n    Gets dosages for medication concepts\n\n    Args:\n        dosage_extractor (DosageExtractor): The dosage extractor object\n        concepts (List[Concept]): List of concepts extracted\n        note (Note): The input note\n\n    Returns:\n        List of concepts with dosages for medication concepts\n    \"\"\"\n\n    for ind, concept in enumerate(concepts):\n        next_med_concept = concepts[ind + 1] if len(concepts) &gt; ind + 1 else None\n        dosage_string = get_dosage_string(concept, next_med_concept, note.text)\n        if len(dosage_string.split()) &gt; 2:\n            concept.dosage = dosage_extractor(dosage_string)\n            concept.category = Category.MEDICATION if concept.dosage is not None else None\n            if concept.dosage is not None:\n                log.debug(\n                    f\"Extracted dosage for medication concept \"\n                    f\"({concept.id} | {concept.name}): {concept.dosage.text} {concept.dosage.dose}\"\n                )\n\n    return concepts\n</code></pre>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.add_numbering_to_name","title":"<code>add_numbering_to_name(concepts)</code>  <code>staticmethod</code>","text":"<p>Adds numbering to the names of problem concepts to control output ordering.</p> <p>Parameters:</p> Name Type Description Default <code>concepts</code> <code>List[Concept]</code> <p>The list of concepts to add numbering to.</p> required <p>Returns:</p> Type Description <code>List[Concept]</code> <p>The list of concepts with numbering added to their names.</p> Source code in <code>miade/annotators.py</code> <pre><code>@staticmethod\ndef add_numbering_to_name(concepts: List[Concept]) -&gt; List[Concept]:\n    \"\"\"\n    Adds numbering to the names of problem concepts to control output ordering.\n\n    Args:\n        concepts (List[Concept]): The list of concepts to add numbering to.\n\n    Returns:\n        The list of concepts with numbering added to their names.\n    \"\"\"\n    # Prepend numbering to problem concepts e.g. 01 asthma, 02 stroke...\n    for i, concept in enumerate(concepts):\n        concept.name = f\"{(i + 1):02} {concept.name}\"\n\n    return concepts\n</code></pre>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.deduplicate","title":"<code>deduplicate(concepts, record_concepts=None)</code>  <code>staticmethod</code>","text":"<p>Removes duplicate concepts from the extracted concepts list by strict ID matching.</p> <p>Parameters:</p> Name Type Description Default <code>concepts</code> <code>List[Concept]</code> <p>The list of extracted concepts.</p> required <code>record_concepts</code> <code>Optional[List[Concept]]</code> <p>The list of concepts from existing EHR records.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Concept]</code> <p>The deduplicated list of concepts.</p> Source code in <code>miade/annotators.py</code> <pre><code>@staticmethod\ndef deduplicate(concepts: List[Concept], record_concepts: Optional[List[Concept]] = None) -&gt; List[Concept]:\n    \"\"\"\n    Removes duplicate concepts from the extracted concepts list by strict ID matching.\n\n    Args:\n        concepts (List[Concept]): The list of extracted concepts.\n        record_concepts (Optional[List[Concept]]): The list of concepts from existing EHR records.\n\n    Returns:\n        The deduplicated list of concepts.\n    \"\"\"\n    if record_concepts is not None:\n        record_ids = {record_concept.id for record_concept in record_concepts}\n        record_names = {record_concept.name for record_concept in record_concepts}\n    else:\n        record_ids = set()\n        record_names = set()\n\n    # Use an OrderedDict to keep track of ids as it preservers original MedCAT order (the order it appears in text)\n    filtered_concepts: List[Concept] = []\n    existing_concepts = OrderedDict()\n\n    # Filter concepts that are in record or exist in concept list\n    for concept in concepts:\n        if concept.id is not None and (concept.id in record_ids or concept.id in existing_concepts):\n            log.debug(f\"Removed concept ({concept.id} | {concept.name}): concept id exists in record\")\n        # check name match for null ids - VTM deduplication\n        elif concept.id is None and (concept.name in record_names or concept.name in existing_concepts.values()):\n            log.debug(f\"Removed concept ({concept.id} | {concept.name}): concept name exists in record\")\n        else:\n            filtered_concepts.append(concept)\n            existing_concepts[concept.id] = concept.name\n\n    return filtered_concepts\n</code></pre>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.filter_concepts_in_numbered_list","title":"<code>filter_concepts_in_numbered_list(concepts, note)</code>  <code>staticmethod</code>","text":"<p>Filters and returns a list of concepts in a numbered list in a note using a two-pointer algorithm.</p> <p>This filters out concepts that may not be relevant given a note that has structured list headings and numbered lists within that. i.e. only return the first line of a numbered list. e.g.     1. CCF -     - had echo on 15/6     - on diuretics will only return the concept CCF as it is the first item in a numbered list</p> <p>Parameters:</p> Name Type Description Default <code>concepts</code> <code>List[Concept]</code> <p>The list of concepts to filter.</p> required <code>note</code> <code>Note</code> <p>The note containing numbered lists.</p> required <p>Returns:</p> Type Description <code>List[Concept]</code> <p>The filtered list of concepts.</p> Source code in <code>miade/annotators.py</code> <pre><code>@staticmethod\ndef filter_concepts_in_numbered_list(concepts: List[Concept], note: Note) -&gt; List[Concept]:\n    \"\"\"\n    Filters and returns a list of concepts in a numbered list in a note using a two-pointer algorithm.\n\n    This filters out concepts that may not be relevant given a note that has structured list headings\n    and numbered lists within that. i.e. only return the first line of a numbered list. e.g.\n        1. CCF -\n        - had echo on 15/6\n        - on diuretics\n    will only return the concept CCF as it is the first item in a numbered list\n\n    Args:\n        concepts (List[Concept]): The list of concepts to filter.\n        note (Note): The note containing numbered lists.\n\n    Returns:\n       The filtered list of concepts.\n    \"\"\"\n    # Check there is a numbered list\n    if len(note.numbered_lists) == 0:\n        return concepts\n\n    # Get the global list ranges of all numbered lists in a note\n    global_list_ranges = [\n        (numbered_list.list_start, numbered_list.list_end) for numbered_list in note.numbered_lists\n    ]\n\n    # Flatten the list items from all numbered lists into a single list and sort them\n    list_items = [item for numbered_list in note.numbered_lists for item in numbered_list.items]\n    list_items.sort(key=lambda x: x.start)\n\n    # Sort the concepts by their start index\n    concepts.sort(key=lambda x: x.start)\n\n    filtered_concepts = []\n    concept_idx, item_idx = 0, 0\n\n    # Iterate through concepts and list items simultaneously\n    while concept_idx &lt; len(concepts) and item_idx &lt; len(list_items):\n        concept = concepts[concept_idx]\n        item = list_items[item_idx]\n\n        # Check if the concept is within the global range of any list\n        if any(start &lt;= concept.start &lt; end for start, end in global_list_ranges):\n            # Check for partial or full overlap between concept and list item\n            if (\n                concept.start &gt;= item.start and concept.end &lt;= item.end\n            ):  # or (concept.start &lt; item.end and concept.end &gt; item.start)\n                # Concept overlaps with or is within the current list item\n                filtered_concepts.append(concept)\n                concept_idx += 1  # Move to the next concept\n            elif concept.end &lt;= item.start:\n                # If the concept ends before the item starts, move to the next concept\n                concept_idx += 1\n            else:\n                # Otherwise, move to the next list item\n                item_idx += 1\n        else:\n            # If concept is not within a numbered list range, skip and return it\n            filtered_concepts.append(concept)\n            concept_idx += 1\n\n    # After iterating, check if there are remaining concepts after the last list item that might not have been added\n    while concept_idx &lt; len(concepts):\n        concept = concepts[concept_idx]\n        if concept.start &gt;= global_list_ranges[-1][1]:\n            filtered_concepts.append(concept)\n        concept_idx += 1\n\n    return filtered_concepts\n</code></pre>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.get_concepts","title":"<code>get_concepts(note)</code>","text":"<p>Extracts concepts from a note using the MedCAT instance.</p> <p>Parameters:</p> Name Type Description Default <code>note</code> <code>Note</code> <p>The input note to extract concepts from.</p> required <p>Returns:</p> Type Description <code>List[Concept]</code> <p>The extracted concepts from the note.</p> Source code in <code>miade/annotators.py</code> <pre><code>def get_concepts(self, note: Note) -&gt; List[Concept]:\n    \"\"\"\n    Extracts concepts from a note using the MedCAT instance.\n\n    Args:\n        note (Note): The input note to extract concepts from.\n\n    Returns:\n        The extracted concepts from the note.\n    \"\"\"\n    concepts: List[Concept] = []\n    for entity in self.cat.get_entities(note)[\"entities\"].values():\n        try:\n            concepts.append(Concept.from_entity(entity))\n            log.debug(f\"Detected concept ({concepts[-1].id} | {concepts[-1].name})\")\n        except ValueError as e:\n            log.warning(f\"Concept skipped: {e}\")\n\n    return concepts\n</code></pre>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.postprocess","title":"<code>postprocess()</code>  <code>abstractmethod</code>","text":"<p>Abstract method that should implement the logic for post-processing extracted concepts.</p> Source code in <code>miade/annotators.py</code> <pre><code>@abstractmethod\ndef postprocess(self):\n    \"\"\"\n    Abstract method that should implement the logic for post-processing extracted concepts.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.preprocess","title":"<code>preprocess(note, refine=True)</code>","text":"<p>Preprocesses a note by cleaning its text and splitting it into paragraphs.</p> <p>Parameters:</p> Name Type Description Default <code>note</code> <code>Note</code> <p>The input note to preprocess.</p> required <code>refine</code> <code>bool</code> <p>Whether to refine the paragraph detection algorithm and allow merging of continuous prose</p> <code>True</code> <p>Returns:</p> Type Description <code>Note</code> <p>The preprocessed note.</p> Source code in <code>miade/annotators.py</code> <pre><code>def preprocess(self, note: Note, refine: bool = True) -&gt; Note:\n    \"\"\"\n    Preprocesses a note by cleaning its text and splitting it into paragraphs.\n\n    Args:\n        note (Note): The input note to preprocess.\n        refine (bool): Whether to refine the paragraph detection algorithm and allow merging of continuous prose\n        paragraphs, merging to paragraphs with empty bodies with the next prose paragraphs. Default True.\n\n    Returns:\n        The preprocessed note.\n    \"\"\"\n    note.process(self.paragraph_regex, refine=refine)\n\n    return note\n</code></pre>"},{"location":"api-reference/annotator/#miade.annotators.Annotator.run_pipeline","title":"<code>run_pipeline()</code>  <code>abstractmethod</code>","text":"<p>Abstract method that runs the annotation pipeline on a given note and returns the extracted concepts.</p> Source code in <code>miade/annotators.py</code> <pre><code>@abstractmethod\ndef run_pipeline(self):\n    \"\"\"\n    Abstract method that runs the annotation pipeline on a given note and returns the extracted concepts.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/concept/","title":"Concept","text":"<p>               Bases: <code>object</code></p> <p>Represents a concept in the system.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>The unique identifier of the concept.</p> <code>name</code> <code>str</code> <p>The name of the concept.</p> <code>category</code> <code>Optional[Enum]</code> <p>The category of the concept (optional).</p> <code>start</code> <code>Optional[int]</code> <p>The start position of the concept (optional).</p> <code>end</code> <code>Optional[int]</code> <p>The end position of the concept (optional).</p> <code>dosage</code> <code>Optional[Dosage]</code> <p>The dosage of the concept (optional).</p> <code>linked_concepts</code> <code>Optional[List[Concept]]</code> <p>The linked concepts of the concept (optional).</p> <code>negex</code> <code>Optional[bool]</code> <p>The negex value of the concept (optional).</p> <code>meta_anns</code> <code>Optional[List[MetaAnnotations]]</code> <p>The meta annotations of the concept (optional).</p> <code>debug_dict</code> <code>Optional[Dict]</code> <p>The debug dictionary of the concept (optional).</p> Source code in <code>miade/concept.py</code> <pre><code>class Concept(object):\n    \"\"\"Represents a concept in the system.\n\n    Attributes:\n        id (str): The unique identifier of the concept.\n        name (str): The name of the concept.\n        category (Optional[Enum]): The category of the concept (optional).\n        start (Optional[int]): The start position of the concept (optional).\n        end (Optional[int]): The end position of the concept (optional).\n        dosage (Optional[Dosage]): The dosage of the concept (optional).\n        linked_concepts (Optional[List[Concept]]): The linked concepts of the concept (optional).\n        negex (Optional[bool]): The negex value of the concept (optional).\n        meta_anns (Optional[List[MetaAnnotations]]): The meta annotations of the concept (optional).\n        debug_dict (Optional[Dict]): The debug dictionary of the concept (optional).\n    \"\"\"\n\n    def __init__(\n        self,\n        id: str,\n        name: str,\n        category: Optional[Enum] = None,\n        start: Optional[int] = None,\n        end: Optional[int] = None,\n        dosage: Optional[Dosage] = None,\n        linked_concepts: Optional[List[Concept]] = None,\n        negex: Optional[bool] = None,\n        meta_anns: Optional[List[MetaAnnotations]] = None,\n        debug_dict: Optional[Dict] = None,\n    ):\n        self.name = name\n        self.id = id\n        self.category = category\n        self.start = start\n        self.end = end\n        self.dosage = dosage\n        self.linked_concepts = linked_concepts\n        self.negex = negex\n        self.meta = meta_anns\n        self.debug = debug_dict\n\n        if linked_concepts is None:\n            self.linked_concepts = []\n\n    @classmethod\n    def from_entity(cls, entity: Dict) -&gt; Concept:\n        \"\"\"\n        Converts an entity dictionary into a Concept object.\n\n        Args:\n            entity (Dict): The entity dictionary containing the necessary information.\n\n        Returns:\n            The Concept object created from the entity dictionary.\n        \"\"\"\n        meta_anns = None\n        if entity[\"meta_anns\"]:\n            meta_anns = [MetaAnnotations(**value) for value in entity[\"meta_anns\"].values()]\n\n        return Concept(\n            id=entity[\"cui\"],\n            name=entity[\n                \"source_value\"\n            ],  # can also use detected_name which is spell checked but delimited by ~ e.g. liver~failure\n            category=None,\n            start=entity[\"start\"],\n            end=entity[\"end\"],\n            negex=entity[\"negex\"] if \"negex\" in entity else None,\n            meta_anns=meta_anns,\n        )\n\n    def __str__(self):\n        return (\n            f\"{{name: {self.name}, id: {self.id}, category: {self.category}, start: {self.start}, end: {self.end},\"\n            f\" dosage: {self.dosage}, linked_concepts: {self.linked_concepts}, negex: {self.negex}, meta: {self.meta}}} \"\n        )\n\n    def __hash__(self):\n        return hash((self.id, self.name, self.category))\n\n    def __eq__(self, other):\n        return self.id == other.id and self.name == other.name and self.category == other.category\n\n    def __lt__(self, other):\n        return int(self.id) &lt; int(other.id)\n\n    def __gt__(self, other):\n        return int(self.id) &gt; int(other.id)\n</code></pre>"},{"location":"api-reference/concept/#miade.concept.Concept.from_entity","title":"<code>from_entity(entity)</code>  <code>classmethod</code>","text":"<p>Converts an entity dictionary into a Concept object.</p> <p>Parameters:</p> Name Type Description Default <code>entity</code> <code>Dict</code> <p>The entity dictionary containing the necessary information.</p> required <p>Returns:</p> Type Description <code>Concept</code> <p>The Concept object created from the entity dictionary.</p> Source code in <code>miade/concept.py</code> <pre><code>@classmethod\ndef from_entity(cls, entity: Dict) -&gt; Concept:\n    \"\"\"\n    Converts an entity dictionary into a Concept object.\n\n    Args:\n        entity (Dict): The entity dictionary containing the necessary information.\n\n    Returns:\n        The Concept object created from the entity dictionary.\n    \"\"\"\n    meta_anns = None\n    if entity[\"meta_anns\"]:\n        meta_anns = [MetaAnnotations(**value) for value in entity[\"meta_anns\"].values()]\n\n    return Concept(\n        id=entity[\"cui\"],\n        name=entity[\n            \"source_value\"\n        ],  # can also use detected_name which is spell checked but delimited by ~ e.g. liver~failure\n        category=None,\n        start=entity[\"start\"],\n        end=entity[\"end\"],\n        negex=entity[\"negex\"] if \"negex\" in entity else None,\n        meta_anns=meta_anns,\n    )\n</code></pre>"},{"location":"api-reference/concept/#category","title":"Category","text":"<p>               Bases: <code>Enum</code></p> Source code in <code>miade/concept.py</code> <pre><code>class Category(Enum):\n    PROBLEM = 1\n    MEDICATION = 2\n    ALLERGY = 3\n    REACTION = 4\n    SEVERITY = 5\n    ALLERGY_TYPE = 6\n</code></pre>"},{"location":"api-reference/dosage/","title":"Dosage","text":"<p>               Bases: <code>object</code></p> <p>Container for drug dosage information</p> Source code in <code>miade/dosage.py</code> <pre><code>class Dosage(object):\n    \"\"\"\n    Container for drug dosage information\n    \"\"\"\n\n    def __init__(\n        self,\n        dose: Optional[Dose],\n        duration: Optional[Duration],\n        frequency: Optional[Frequency],\n        route: Optional[Route],\n        text: Optional[str] = None,\n    ):\n        self.text = text\n        self.dose = dose\n        self.duration = duration\n        self.frequency = frequency\n        self.route = route\n\n    @classmethod\n    def from_doc(cls, doc: Doc, calculate: bool = True):\n        \"\"\"\n        Parses dosage from a spacy doc object.\n\n        Args:\n            doc (Doc): Spacy doc object with processed dosage text.\n            calculate (bool, optional): Whether to calculate duration if total and daily dose is given. Defaults to True.\n\n        Returns:\n            An instance of the class with the parsed dosage information.\n\n        \"\"\"\n        quantities = []\n        units = []\n        dose_start = 1000\n        dose_end = 0\n        daily_dose = None\n        total_dose = None\n        route_text = None\n        duration_text = None\n\n        for ent in doc.ents:\n            if ent.label_ == \"DOSAGE\":\n                if ent._.total_dose:\n                    total_dose = float(ent.text)\n                else:\n                    quantities.append(ent.text)\n                    # get span of full dosage string - not strictly needed but nice to have\n                    if ent.start &lt; dose_start:\n                        dose_start = ent.start\n                    if ent.end &gt; dose_end:\n                        dose_end = ent.end\n            elif ent.label_ == \"FORM\":\n                if ent._.total_dose:\n                    # de facto unit is in total dose\n                    units = [ent.text]\n                else:\n                    units.append(ent.text)\n                    if ent.start &lt; dose_start:\n                        dose_start = ent.start\n                    if ent.end &gt; dose_end:\n                        dose_end = ent.end\n            elif ent.label_ == \"DURATION\":\n                duration_text = ent.text\n            elif ent.label_ == \"ROUTE\":\n                route_text = ent.text\n\n        dose = parse_dose(\n            text=\" \".join(doc.text.split()[dose_start:dose_end]),\n            quantities=quantities,\n            units=units,\n            results=doc._.results,\n        )\n\n        frequency = parse_frequency(text=doc.text, results=doc._.results)\n\n        route = parse_route(text=route_text, dose=dose)\n\n        # technically not information recorded so will keep as an option\n        if calculate:\n            # if duration not given in text could extract this from total dose if given\n            if total_dose is not None and dose is not None and doc._.results[\"freq\"]:\n                if dose.value is not None:\n                    daily_dose = float(dose.value) * (round(doc._.results[\"freq\"] / doc._.results[\"time\"]))\n                elif dose.high is not None:\n                    daily_dose = float(dose.high) * (round(doc._.results[\"freq\"] / doc._.results[\"time\"]))\n\n        duration = parse_duration(\n            text=duration_text,\n            results=doc._.results,\n            total_dose=total_dose,\n            daily_dose=daily_dose,\n        )\n\n        return cls(\n            text=doc._.original_text,\n            dose=dose,\n            duration=duration,\n            frequency=frequency,\n            route=route,\n        )\n\n    def __str__(self):\n        return f\"{self.__dict__}\"\n\n    def __eq__(self, other):\n        return self.__dict__ == other.__dict__\n</code></pre>"},{"location":"api-reference/dosage/#miade.dosage.Dosage.from_doc","title":"<code>from_doc(doc, calculate=True)</code>  <code>classmethod</code>","text":"<p>Parses dosage from a spacy doc object.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>Spacy doc object with processed dosage text.</p> required <code>calculate</code> <code>bool</code> <p>Whether to calculate duration if total and daily dose is given. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <p>An instance of the class with the parsed dosage information.</p> Source code in <code>miade/dosage.py</code> <pre><code>@classmethod\ndef from_doc(cls, doc: Doc, calculate: bool = True):\n    \"\"\"\n    Parses dosage from a spacy doc object.\n\n    Args:\n        doc (Doc): Spacy doc object with processed dosage text.\n        calculate (bool, optional): Whether to calculate duration if total and daily dose is given. Defaults to True.\n\n    Returns:\n        An instance of the class with the parsed dosage information.\n\n    \"\"\"\n    quantities = []\n    units = []\n    dose_start = 1000\n    dose_end = 0\n    daily_dose = None\n    total_dose = None\n    route_text = None\n    duration_text = None\n\n    for ent in doc.ents:\n        if ent.label_ == \"DOSAGE\":\n            if ent._.total_dose:\n                total_dose = float(ent.text)\n            else:\n                quantities.append(ent.text)\n                # get span of full dosage string - not strictly needed but nice to have\n                if ent.start &lt; dose_start:\n                    dose_start = ent.start\n                if ent.end &gt; dose_end:\n                    dose_end = ent.end\n        elif ent.label_ == \"FORM\":\n            if ent._.total_dose:\n                # de facto unit is in total dose\n                units = [ent.text]\n            else:\n                units.append(ent.text)\n                if ent.start &lt; dose_start:\n                    dose_start = ent.start\n                if ent.end &gt; dose_end:\n                    dose_end = ent.end\n        elif ent.label_ == \"DURATION\":\n            duration_text = ent.text\n        elif ent.label_ == \"ROUTE\":\n            route_text = ent.text\n\n    dose = parse_dose(\n        text=\" \".join(doc.text.split()[dose_start:dose_end]),\n        quantities=quantities,\n        units=units,\n        results=doc._.results,\n    )\n\n    frequency = parse_frequency(text=doc.text, results=doc._.results)\n\n    route = parse_route(text=route_text, dose=dose)\n\n    # technically not information recorded so will keep as an option\n    if calculate:\n        # if duration not given in text could extract this from total dose if given\n        if total_dose is not None and dose is not None and doc._.results[\"freq\"]:\n            if dose.value is not None:\n                daily_dose = float(dose.value) * (round(doc._.results[\"freq\"] / doc._.results[\"time\"]))\n            elif dose.high is not None:\n                daily_dose = float(dose.high) * (round(doc._.results[\"freq\"] / doc._.results[\"time\"]))\n\n    duration = parse_duration(\n        text=duration_text,\n        results=doc._.results,\n        total_dose=total_dose,\n        daily_dose=daily_dose,\n    )\n\n    return cls(\n        text=doc._.original_text,\n        dose=dose,\n        duration=duration,\n        frequency=frequency,\n        route=route,\n    )\n</code></pre>"},{"location":"api-reference/dosageextractor/","title":"DosageExtractor","text":"<p>Parses and extracts drug dosage</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>str</code> <p>The name of the model to be used for dosage extraction.</p> <code>dosage_extractor</code> <code>Language</code> <p>The Spacy pipeline for dosage extraction.</p> Source code in <code>miade/dosageextractor.py</code> <pre><code>class DosageExtractor:\n    \"\"\"\n    Parses and extracts drug dosage\n\n    Attributes:\n        model (str): The name of the model to be used for dosage extraction.\n        dosage_extractor (Language): The Spacy pipeline for dosage extraction.\n    \"\"\"\n\n    def __init__(self, model: str = \"en_core_med7_lg\"):\n        self.model = model\n        self.dosage_extractor = self._create_drugdoseade_pipeline()\n\n    def _create_drugdoseade_pipeline(self) -&gt; Language:\n        \"\"\"\n        Creates a spacy pipeline with given model (default med7)\n        and customised pipeline components for dosage extraction\n\n        Returns:\n            nlp (spacy.Language): The Spacy pipeline for dosage extraction.\n        \"\"\"\n        nlp = spacy.load(self.model)\n        nlp.add_pipe(\"preprocessor\", first=True)\n        nlp.add_pipe(\"pattern_matcher\", before=\"ner\")\n        nlp.add_pipe(\"entities_refiner\", after=\"ner\")\n\n        log.info(f\"Loaded drug dosage extractor with model {self.model}\")\n\n        return nlp\n\n    def extract(self, text: str, calculate: bool = True) -&gt; Optional[Dosage]:\n        \"\"\"\n        Processes a string that contains dosage instructions (excluding drug concept as this is handled by core)\n\n        Args:\n            text (str): The string containing dosage instructions.\n            calculate (bool): Whether to calculate duration from total and daily dose, if given.\n\n        Returns:\n            The dosage object with parsed dosages in CDA format.\n        \"\"\"\n        doc = self.dosage_extractor(text)\n\n        log.debug(f\"NER results: {[(e.text, e.label_, e._.total_dose) for e in doc.ents]}\")\n        log.debug(f\"Lookup results: {doc._.results}\")\n\n        dosage = Dosage.from_doc(doc=doc, calculate=calculate)\n\n        if all(v is None for v in [dosage.dose, dosage.frequency, dosage.route, dosage.duration]):\n            return None\n\n        return dosage\n\n    def __call__(self, text: str, calculate: bool = True):\n        return self.extract(text, calculate)\n</code></pre>"},{"location":"api-reference/dosageextractor/#miade.dosageextractor.DosageExtractor.extract","title":"<code>extract(text, calculate=True)</code>","text":"<p>Processes a string that contains dosage instructions (excluding drug concept as this is handled by core)</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The string containing dosage instructions.</p> required <code>calculate</code> <code>bool</code> <p>Whether to calculate duration from total and daily dose, if given.</p> <code>True</code> <p>Returns:</p> Type Description <code>Optional[Dosage]</code> <p>The dosage object with parsed dosages in CDA format.</p> Source code in <code>miade/dosageextractor.py</code> <pre><code>def extract(self, text: str, calculate: bool = True) -&gt; Optional[Dosage]:\n    \"\"\"\n    Processes a string that contains dosage instructions (excluding drug concept as this is handled by core)\n\n    Args:\n        text (str): The string containing dosage instructions.\n        calculate (bool): Whether to calculate duration from total and daily dose, if given.\n\n    Returns:\n        The dosage object with parsed dosages in CDA format.\n    \"\"\"\n    doc = self.dosage_extractor(text)\n\n    log.debug(f\"NER results: {[(e.text, e.label_, e._.total_dose) for e in doc.ents]}\")\n    log.debug(f\"Lookup results: {doc._.results}\")\n\n    dosage = Dosage.from_doc(doc=doc, calculate=calculate)\n\n    if all(v is None for v in [dosage.dose, dosage.frequency, dosage.route, dosage.duration]):\n        return None\n\n    return dosage\n</code></pre>"},{"location":"api-reference/medsallergiesannotator/","title":"MedsAllergiesAnnotator","text":"<p>               Bases: <code>Annotator</code></p> <p>Annotator class for medication and allergy concepts.</p> <p>This class extends the <code>Annotator</code> base class and provides methods for running a pipeline of annotation tasks on a given note, as well as validating and converting concepts related to medications and allergies.</p> <p>Attributes:</p> Name Type Description <code>valid_meds</code> <code>List[int]</code> <p>A list of valid medication IDs.</p> <code>reactions_subset_lookup</code> <code>Dict[int, str]</code> <p>A dictionary mapping reaction IDs to their corresponding subset IDs.</p> <code>allergens_subset_lookup</code> <code>Dict[int, str]</code> <p>A dictionary mapping allergen IDs to their corresponding subset IDs.</p> <code>allergy_type_lookup</code> <code>Dict[str, List[str]]</code> <p>A dictionary mapping allergen types to their corresponding codes.</p> <code>vtm_to_vmp_lookup</code> <code>Dict[str, str]</code> <p>A dictionary mapping VTM (Virtual Therapeutic Moiety) IDs to VMP (Virtual Medicinal Product) IDs.</p> <code>vtm_to_text_lookup</code> <code>Dict[str, str]</code> <p>A dictionary mapping VTM IDs to their corresponding text.</p> Source code in <code>miade/annotators.py</code> <pre><code>class MedsAllergiesAnnotator(Annotator):\n    \"\"\"\n    Annotator class for medication and allergy concepts.\n\n    This class extends the `Annotator` base class and provides methods for running a pipeline of\n    annotation tasks on a given note, as well as validating and converting concepts related to\n    medications and allergies.\n\n    Attributes:\n        valid_meds (List[int]): A list of valid medication IDs.\n        reactions_subset_lookup (Dict[int, str]): A dictionary mapping reaction IDs to their corresponding subset IDs.\n        allergens_subset_lookup (Dict[int, str]): A dictionary mapping allergen IDs to their corresponding subset IDs.\n        allergy_type_lookup (Dict[str, List[str]]): A dictionary mapping allergen types to their corresponding codes.\n        vtm_to_vmp_lookup (Dict[str, str]): A dictionary mapping VTM (Virtual Therapeutic Moiety) IDs to VMP (Virtual Medicinal Product) IDs.\n        vtm_to_text_lookup (Dict[str, str]): A dictionary mapping VTM IDs to their corresponding text.\n    \"\"\"\n\n    def __init__(self, cat: CAT, config: AnnotatorConfig = None):\n        super().__init__(cat, config)\n        self._load_med_allergy_lookup_data()\n\n    @property\n    def concept_types(self) -&gt; List[Category]:\n        \"\"\"\n        Returns a list of concept types.\n\n        Returns:\n            [Category.MEDICATION, Category.ALLERGY, Category.REACTION]\n        \"\"\"\n        return [Category.MEDICATION, Category.ALLERGY, Category.REACTION]\n\n    @property\n    def pipeline(self) -&gt; List[str]:\n        \"\"\"\n        Returns a list of annotators in the pipeline.\n\n        The annotators are executed in the order they appear in the list.\n\n        Returns:\n            [\"preprocessor\", \"medcat\", \"list_cleaner\", \"paragrapher\", \"postprocessor\", \"dosage_extractor\", \"vtm_converter\", \"deduplicator\"]\n        \"\"\"\n        return [\n            \"preprocessor\",\n            \"medcat\",\n            \"list_cleaner\",\n            \"paragrapher\",\n            \"postprocessor\",\n            \"dosage_extractor\",\n            \"vtm_converter\",\n            \"deduplicator\",\n        ]\n\n    def run_pipeline(\n        self,\n        note: Note,\n        record_concepts: Optional[List[Concept]] = None,\n        dosage_extractor: Optional[DosageExtractor] = None,\n    ) -&gt; List[Concept]:\n        \"\"\"\n        Runs the annotation pipeline on the given note.\n\n        Args:\n            note (Note): The input note to run the pipeline on.\n            record_concepts (Optional[List[Concept]]): The list of previously recorded concepts.\n            dosage_extractor (Optional[DosageExtractor]): The dosage extractor function.\n\n        Returns:\n            The list of annotated concepts.\n        \"\"\"\n        concepts: List[Concept] = []\n\n        for pipe in self.pipeline:\n            if pipe not in self.config.disable:\n                if pipe == \"preprocessor\":\n                    note = self.preprocess(note=note)\n                elif pipe == \"medcat\":\n                    concepts = self.get_concepts(note=note)\n                elif pipe == \"list_cleaner\":\n                    concepts = self.filter_concepts_in_numbered_list(concepts=concepts, note=note)\n                elif pipe == \"paragrapher\":\n                    concepts = self.process_paragraphs(note=note, concepts=concepts)\n                elif pipe == \"postprocessor\":\n                    concepts = self.postprocess(concepts=concepts, note=note)\n                elif pipe == \"deduplicator\":\n                    concepts = self.deduplicate(concepts=concepts, record_concepts=record_concepts)\n                elif pipe == \"vtm_converter\":\n                    concepts = self.convert_VTM_to_VMP_or_text(concepts=concepts)\n                elif pipe == \"dosage_extractor\" and dosage_extractor is not None:\n                    concepts = self.add_dosages_to_concepts(\n                        dosage_extractor=dosage_extractor, concepts=concepts, note=note\n                    )\n\n        return concepts\n\n    def _load_med_allergy_lookup_data(self) -&gt; None:\n        \"\"\"\n        Loads the medication and allergy lookup data.\n        \"\"\"\n        self.valid_meds = load_lookup_data(\n            self.lookup_data_path + \"valid_meds.csv\", is_package_data=self.use_package_data, no_header=True\n        )\n        self.reactions_subset_lookup = load_lookup_data(\n            self.lookup_data_path + \"reactions_subset.csv\", is_package_data=self.use_package_data, as_dict=True\n        )\n        self.allergens_subset_lookup = load_lookup_data(\n            self.lookup_data_path + \"allergens_subset.csv\", is_package_data=self.use_package_data, as_dict=True\n        )\n        self.allergy_type_lookup = load_allergy_type_combinations(\n            self.lookup_data_path + \"allergy_type.csv\", is_package_data=self.use_package_data\n        )\n        self.vtm_to_vmp_lookup = load_lookup_data(\n            self.lookup_data_path + \"vtm_to_vmp.csv\", is_package_data=self.use_package_data\n        )\n        self.vtm_to_text_lookup = load_lookup_data(\n            self.lookup_data_path + \"vtm_to_text.csv\", is_package_data=self.use_package_data, as_dict=True\n        )\n\n    def _validate_meds(self, concept) -&gt; bool:\n        \"\"\"\n        Validates if the concept is a valid medication.\n\n        Args:\n            concept: The concept to validate.\n\n        Returns:\n            True if the concept is a valid medication, False otherwise.\n        \"\"\"\n        # check if substance is valid med\n        if int(concept.id) in self.valid_meds.values:\n            return True\n        return False\n\n    def _validate_and_convert_substance(self, concept) -&gt; bool:\n        \"\"\"\n        Validates and converts a substance concept for allergy.\n\n        Args:\n            concept: The substance concept to be validated and converted.\n\n        Returns:\n            True if the substance is valid and converted successfully, False otherwise.\n        \"\"\"\n        # check if substance is valid substance for allergy - if it is, convert it to Epic subset and return that concept\n        lookup_result = self.allergens_subset_lookup.get(int(concept.id))\n        if lookup_result is not None:\n            log.debug(\n                f\"Converted concept ({concept.id} | {concept.name}) to \"\n                f\"({lookup_result['subsetId']} | {concept.name}): valid Epic allergen subset\"\n            )\n            concept.id = str(lookup_result[\"subsetId\"])\n\n            # then check the allergen type from lookup result - e.g. drug, food\n            try:\n                concept.category = AllergenType(str(lookup_result[\"allergenType\"]).lower())\n                log.debug(\n                    f\"Assigned substance concept ({concept.id} | {concept.name}) \"\n                    f\"to allergen type category {concept.category}\"\n                )\n            except ValueError as e:\n                log.warning(f\"Allergen type not found for {concept.__str__()}: {e}\")\n\n            return True\n        else:\n            log.warning(f\"No lookup subset found for substance ({concept.id} | {concept.name})\")\n            return False\n\n    def _validate_and_convert_reaction(self, concept) -&gt; bool:\n        \"\"\"\n        Validates and converts a reaction concept to the Epic subset.\n\n        Args:\n            concept: The concept to be validated and converted.\n\n        Returns:\n            True if the concept is a valid reaction and successfully converted to the Epic subset,\n                  False otherwise.\n        \"\"\"\n        # check if substance is valid reaction - if it is, convert it to Epic subset and return that concept\n        lookup_result = self.reactions_subset_lookup.get(int(concept.id), None)\n        if lookup_result is not None:\n            log.debug(\n                f\"Converted concept ({concept.id} | {concept.name}) to \"\n                f\"({lookup_result} | {concept.name}): valid Epic reaction subset\"\n            )\n            concept.id = str(lookup_result)\n            return True\n        else:\n            log.warning(f\"Reaction not found in Epic subset conversion for concept {concept.__str__()}\")\n            return False\n\n    def _validate_and_convert_concepts(self, concept: Concept) -&gt; Concept:\n        \"\"\"\n        Validates and converts the given concept based on its metadata annotations.\n\n        Args:\n            concept (Concept): The concept to be validated and converted.\n\n        Returns:\n            The validated and converted concept.\n\n        \"\"\"\n        meta_ann_values = [meta_ann.value for meta_ann in concept.meta] if concept.meta is not None else []\n\n        # assign categories\n        if SubstanceCategory.ADVERSE_REACTION in meta_ann_values:\n            if self._validate_and_convert_substance(concept):\n                self._convert_allergy_type_to_code(concept)\n                self._convert_allergy_severity_to_code(concept)\n                concept.category = Category.ALLERGY\n            else:\n                log.warning(f\"Double-checking if concept ({concept.id} | {concept.name}) is in reaction subset\")\n                if self._validate_and_convert_reaction(concept) and (\n                    ReactionPos.BEFORE_SUBSTANCE in meta_ann_values or ReactionPos.AFTER_SUBSTANCE in meta_ann_values\n                ):\n                    concept.category = Category.REACTION\n                else:\n                    log.warning(\n                        f\"Reaction concept ({concept.id} | {concept.name}) not in subset or reaction_pos is NOT_REACTION\"\n                    )\n        if SubstanceCategory.TAKING in meta_ann_values:\n            if self._validate_meds(concept):\n                concept.category = Category.MEDICATION\n        if SubstanceCategory.NOT_SUBSTANCE in meta_ann_values and (\n            ReactionPos.BEFORE_SUBSTANCE in meta_ann_values or ReactionPos.AFTER_SUBSTANCE in meta_ann_values\n        ):\n            if self._validate_and_convert_reaction(concept):\n                concept.category = Category.REACTION\n\n        return concept\n\n    @staticmethod\n    def _link_reactions_to_allergens(concept_list: List[Concept], note: Note, link_distance: int = 5) -&gt; List[Concept]:\n        \"\"\"\n        Links reaction concepts to allergen concepts based on their proximity in the given concept list.\n\n        Args:\n            concept_list (List[Concept]): The list of concepts to search for reaction and allergen concepts.\n            note (Note): The note object containing the text.\n            link_distance (int, optional): The maximum distance between a reaction and an allergen to be considered linked.\n                Defaults to 5.\n\n        Returns:\n            The updated concept list with reaction concepts removed and linked to their corresponding allergen concepts.\n        \"\"\"\n        allergy_concepts = [concept for concept in concept_list if concept.category == Category.ALLERGY]\n        reaction_concepts = [concept for concept in concept_list if concept.category == Category.REACTION]\n\n        for reaction_concept in reaction_concepts:\n            nearest_allergy_concept = None\n            min_distance = inf\n            meta_ann_values = (\n                [meta_ann.value for meta_ann in reaction_concept.meta] if reaction_concept.meta is not None else []\n            )\n\n            for allergy_concept in allergy_concepts:\n                # skip if allergy is after and meta is before_substance\n                if ReactionPos.BEFORE_SUBSTANCE in meta_ann_values and allergy_concept.start &lt; reaction_concept.start:\n                    continue\n                # skip if allergy is before and meta is after_substance\n                elif ReactionPos.AFTER_SUBSTANCE in meta_ann_values and allergy_concept.start &gt; reaction_concept.start:\n                    continue\n                else:\n                    distance = calculate_word_distance(\n                        reaction_concept.start, reaction_concept.end, allergy_concept.start, allergy_concept.end, note\n                    )\n                    log.debug(\n                        f\"Calculated distance between reaction {reaction_concept.name} \"\n                        f\"and allergen {allergy_concept.name}: {distance}\"\n                    )\n                    if distance == -1:\n                        log.warning(\n                            f\"Indices for {reaction_concept.name} or {allergy_concept.name} invalid: \"\n                            f\"({reaction_concept.start}, {reaction_concept.end})\"\n                            f\"({allergy_concept.start}, {allergy_concept.end})\"\n                        )\n                        continue\n\n                    if distance &lt;= link_distance and distance &lt; min_distance:\n                        min_distance = distance\n                        nearest_allergy_concept = allergy_concept\n\n            if nearest_allergy_concept is not None:\n                nearest_allergy_concept.linked_concepts.append(reaction_concept)\n                log.debug(\n                    f\"Linked reaction concept {reaction_concept.name} to \"\n                    f\"allergen concept {nearest_allergy_concept.name}\"\n                )\n\n        # Remove the linked REACTION concepts from the main list\n        updated_concept_list = [concept for concept in concept_list if concept.category != Category.REACTION]\n\n        return updated_concept_list\n\n    @staticmethod\n    def _convert_allergy_severity_to_code(concept: Concept) -&gt; bool:\n        \"\"\"\n        Converts allergy severity to corresponding codes and links them to the concept.\n\n        Args:\n            concept (Concept): The concept to convert severity for.\n\n        Returns:\n            True if the conversion is successful, False otherwise.\n        \"\"\"\n        meta_ann_values = [meta_ann.value for meta_ann in concept.meta] if concept.meta is not None else []\n        if Severity.MILD in meta_ann_values:\n            concept.linked_concepts.append(Concept(id=\"L\", name=\"Low\", category=Category.SEVERITY))\n        elif Severity.MODERATE in meta_ann_values:\n            concept.linked_concepts.append(Concept(id=\"M\", name=\"Moderate\", category=Category.SEVERITY))\n        elif Severity.SEVERE in meta_ann_values:\n            concept.linked_concepts.append(Concept(id=\"H\", name=\"High\", category=Category.SEVERITY))\n        elif Severity.UNSPECIFIED in meta_ann_values:\n            return True\n        else:\n            log.warning(f\"No severity annotation associated with ({concept.id} | {concept.name})\")\n            return False\n\n        log.debug(\n            f\"Linked severity concept ({concept.linked_concepts[-1].id} | {concept.linked_concepts[-1].name}) \"\n            f\"to allergen concept ({concept.id} | {concept.name}): valid meta model output\"\n        )\n\n        return True\n\n    def _convert_allergy_type_to_code(self, concept: Concept) -&gt; bool:\n        \"\"\"\n        Converts the allergy type of a concept to a code and adds it as a linked concept.\n\n        Args:\n            concept (Concept): The concept whose allergy type needs to be converted.\n\n        Returns:\n            True if the conversion and linking were successful, False otherwise.\n        \"\"\"\n        # get the ALLERGYTYPE meta-annotation\n        allergy_type = [meta_ann for meta_ann in concept.meta if meta_ann.name == \"allergy_type\"]\n        if len(allergy_type) != 1:\n            log.warning(\n                f\"Unable to map allergy type code: allergy_type meta-annotation \"\n                f\"not found for concept {concept.__str__()}\"\n            )\n            return False\n        else:\n            allergy_type = allergy_type[0].value\n\n        # perform lookup with ALLERGYTYPE and AllergenType combination\n        lookup_combination: Tuple[str, str] = (concept.category.value, allergy_type.value)\n        allergy_type_lookup_result = self.allergy_type_lookup.get(lookup_combination)\n\n        # add resulting allergy type concept as to linked_concept\n        if allergy_type_lookup_result is not None:\n            concept.linked_concepts.append(\n                Concept(\n                    id=str(allergy_type_lookup_result[0]),\n                    name=allergy_type_lookup_result[1],\n                    category=Category.ALLERGY_TYPE,\n                )\n            )\n            log.debug(\n                f\"Linked allergy_type concept ({allergy_type_lookup_result[0]} | {allergy_type_lookup_result[1]})\"\n                f\" to allergen concept ({concept.id} | {concept.name}): valid meta model output + allergytype lookup\"\n            )\n        else:\n            log.warning(f\"Allergen and adverse reaction type combination not found: {lookup_combination}\")\n\n        return True\n\n    def _process_meta_ann_by_paragraph(self, concept: Concept, paragraph: Paragraph):\n        \"\"\"\n        Process the meta annotations for a given concept and paragraph.\n\n        Args:\n            concept (Concept): The concept object.\n            paragraph (Paragraph): The paragraph object.\n\n        Returns:\n            None\n        \"\"\"\n        # if paragraph is structured meds to convert to corresponding relevance\n        if paragraph.type in self.structured_med_lists:\n            for meta in concept.meta:\n                if meta.name == \"substance_category\" and meta.value in [\n                    SubstanceCategory.TAKING,\n                    SubstanceCategory.IRRELEVANT,\n                ]:\n                    new_relevance = self.structured_med_lists[paragraph.type]\n                    if meta.value != new_relevance:\n                        log.debug(\n                            f\"Converted {meta.value} to \"\n                            f\"{new_relevance} for concept ({concept.id} | {concept.name}): \"\n                            f\"paragraph is {paragraph.type}\"\n                        )\n                        meta.value = new_relevance\n        # if paragraph is probs or irrelevant section, convert substance to irrelevant\n        elif paragraph.type in self.structured_prob_lists or paragraph.type in self.irrelevant_paragraphs:\n            for meta in concept.meta:\n                if meta.name == \"substance_category\" and meta.value != SubstanceCategory.IRRELEVANT:\n                    log.debug(\n                        f\"Converted {meta.value} to \"\n                        f\"{SubstanceCategory.IRRELEVANT} for concept ({concept.id} | {concept.name}): \"\n                        f\"paragraph is {paragraph.type}\"\n                    )\n                    meta.value = SubstanceCategory.IRRELEVANT\n\n    def process_paragraphs(self, note: Note, concepts: List[Concept]) -&gt; List[Concept]:\n        \"\"\"\n        Process the paragraphs in a note and update the list of concepts.\n\n        Args:\n            note (Note): The note object containing the paragraphs.\n            concepts (List[Concept]): The list of concepts to be updated.\n\n        Returns:\n            The updated list of concepts.\n        \"\"\"\n        for paragraph in note.paragraphs:\n            for concept in concepts:\n                if concept.start &gt;= paragraph.start and concept.end &lt;= paragraph.end:\n                    # log.debug(f\"({concept.name} | {concept.id}) is in {paragraph.type}\")\n                    if concept.meta:\n                        self._process_meta_ann_by_paragraph(concept, paragraph)\n\n        return concepts\n\n    def postprocess(self, concepts: List[Concept], note: Note) -&gt; List[Concept]:\n        \"\"\"\n        Postprocesses a list of concepts and links reactions to allergens.\n\n        Args:\n            concepts (List[Concept]): The list of concepts to be postprocessed.\n            note (Note): The note object associated with the concepts.\n\n        Returns:\n           The postprocessed list of concepts.\n        \"\"\"\n        # deepcopy so we still have reference to original list of concepts\n        all_concepts = deepcopy(concepts)\n        processed_concepts = []\n\n        for concept in all_concepts:\n            concept = self._validate_and_convert_concepts(concept)\n            processed_concepts.append(concept)\n\n        processed_concepts = self._link_reactions_to_allergens(processed_concepts, note)\n\n        return processed_concepts\n\n    def convert_VTM_to_VMP_or_text(self, concepts: List[Concept]) -&gt; List[Concept]:\n        \"\"\"\n        Converts medication concepts from VTM (Virtual Therapeutic Moiety) to VMP (Virtual Medicinal Product) or text.\n\n        Args:\n            concepts (List[Concept]): A list of medication concepts.\n\n        Returns:\n            A list of medication concepts with updated IDs, names, and dosages.\n\n        \"\"\"\n        # Get medication concepts\n        med_concepts = [concept for concept in concepts if concept.category == Category.MEDICATION]\n        self.vtm_to_vmp_lookup[\"dose\"] = self.vtm_to_vmp_lookup[\"dose\"].astype(float)\n\n        med_concepts_with_dose = []\n        # I don't know man...Need to improve dosage methods\n        for concept in med_concepts:\n            if concept.dosage is not None:\n                if concept.dosage.dose:\n                    if concept.dosage.dose.value is not None and concept.dosage.dose.unit is not None:\n                        med_concepts_with_dose.append(concept)\n\n        med_concepts_no_dose = [concept for concept in concepts if concept not in med_concepts_with_dose]\n\n        # Create a temporary DataFrame to match vtmId, dose, and unit\n        temp_df = pd.DataFrame(\n            {\n                \"vtmId\": [int(concept.id) for concept in med_concepts_with_dose],\n                \"dose\": [float(concept.dosage.dose.value) for concept in med_concepts_with_dose],\n                \"unit\": [concept.dosage.dose.unit for concept in med_concepts_with_dose],\n            }\n        )\n\n        # Merge with the lookup df to get vmpId\n        merged_df = temp_df.merge(self.vtm_to_vmp_lookup, on=[\"vtmId\", \"dose\", \"unit\"], how=\"left\")\n\n        # Update id in the concepts list\n        for index, concept in enumerate(med_concepts_with_dose):\n            # Convert VTM to VMP id\n            vmp_id = merged_df.at[index, \"vmpId\"]\n            if not pd.isna(vmp_id):\n                log.debug(\n                    f\"Converted ({concept.id} | {concept.name}) to \"\n                    f\"({int(vmp_id)} | {concept.name + ' ' + str(int(concept.dosage.dose.value)) + concept.dosage.dose.unit} \"\n                    f\"tablets): valid extracted dosage + VMP lookup\"\n                )\n                concept.id = str(int(vmp_id))\n                concept.name += \" \" + str(int(concept.dosage.dose.value)) + str(concept.dosage.dose.unit) + \" tablets\"\n                # If found VMP match change the dosage to 1 tablet\n                concept.dosage.dose.value = 1\n                concept.dosage.dose.unit = \"{tbl}\"\n            else:\n                # If no match with dose convert to text\n                lookup_result = self.vtm_to_text_lookup.get(int(concept.id))\n                if lookup_result is not None:\n                    log.debug(\n                        f\"Converted ({concept.id} | {concept.name}) to (None | {lookup_result}: no match to VMP dosage lookup)\"\n                    )\n                    concept.id = None\n                    concept.name = lookup_result\n\n        # Convert rest of VTMs that have no dose for VMP conversion to text\n        for concept in med_concepts_no_dose:\n            lookup_result = self.vtm_to_text_lookup.get(int(concept.id))\n            if lookup_result is not None:\n                log.debug(f\"Converted ({concept.id} | {concept.name}) to (None | {lookup_result}): no dosage detected\")\n                concept.id = None\n                concept.name = lookup_result\n\n        return concepts\n</code></pre>"},{"location":"api-reference/medsallergiesannotator/#miade.annotators.MedsAllergiesAnnotator.concept_types","title":"<code>concept_types</code>  <code>property</code>","text":"<p>Returns a list of concept types.</p> <p>Returns:</p> Type Description <code>List[Category]</code> <p>[Category.MEDICATION, Category.ALLERGY, Category.REACTION]</p>"},{"location":"api-reference/medsallergiesannotator/#miade.annotators.MedsAllergiesAnnotator.pipeline","title":"<code>pipeline</code>  <code>property</code>","text":"<p>Returns a list of annotators in the pipeline.</p> <p>The annotators are executed in the order they appear in the list.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>[\"preprocessor\", \"medcat\", \"list_cleaner\", \"paragrapher\", \"postprocessor\", \"dosage_extractor\", \"vtm_converter\", \"deduplicator\"]</p>"},{"location":"api-reference/medsallergiesannotator/#miade.annotators.MedsAllergiesAnnotator.convert_VTM_to_VMP_or_text","title":"<code>convert_VTM_to_VMP_or_text(concepts)</code>","text":"<p>Converts medication concepts from VTM (Virtual Therapeutic Moiety) to VMP (Virtual Medicinal Product) or text.</p> <p>Parameters:</p> Name Type Description Default <code>concepts</code> <code>List[Concept]</code> <p>A list of medication concepts.</p> required <p>Returns:</p> Type Description <code>List[Concept]</code> <p>A list of medication concepts with updated IDs, names, and dosages.</p> Source code in <code>miade/annotators.py</code> <pre><code>def convert_VTM_to_VMP_or_text(self, concepts: List[Concept]) -&gt; List[Concept]:\n    \"\"\"\n    Converts medication concepts from VTM (Virtual Therapeutic Moiety) to VMP (Virtual Medicinal Product) or text.\n\n    Args:\n        concepts (List[Concept]): A list of medication concepts.\n\n    Returns:\n        A list of medication concepts with updated IDs, names, and dosages.\n\n    \"\"\"\n    # Get medication concepts\n    med_concepts = [concept for concept in concepts if concept.category == Category.MEDICATION]\n    self.vtm_to_vmp_lookup[\"dose\"] = self.vtm_to_vmp_lookup[\"dose\"].astype(float)\n\n    med_concepts_with_dose = []\n    # I don't know man...Need to improve dosage methods\n    for concept in med_concepts:\n        if concept.dosage is not None:\n            if concept.dosage.dose:\n                if concept.dosage.dose.value is not None and concept.dosage.dose.unit is not None:\n                    med_concepts_with_dose.append(concept)\n\n    med_concepts_no_dose = [concept for concept in concepts if concept not in med_concepts_with_dose]\n\n    # Create a temporary DataFrame to match vtmId, dose, and unit\n    temp_df = pd.DataFrame(\n        {\n            \"vtmId\": [int(concept.id) for concept in med_concepts_with_dose],\n            \"dose\": [float(concept.dosage.dose.value) for concept in med_concepts_with_dose],\n            \"unit\": [concept.dosage.dose.unit for concept in med_concepts_with_dose],\n        }\n    )\n\n    # Merge with the lookup df to get vmpId\n    merged_df = temp_df.merge(self.vtm_to_vmp_lookup, on=[\"vtmId\", \"dose\", \"unit\"], how=\"left\")\n\n    # Update id in the concepts list\n    for index, concept in enumerate(med_concepts_with_dose):\n        # Convert VTM to VMP id\n        vmp_id = merged_df.at[index, \"vmpId\"]\n        if not pd.isna(vmp_id):\n            log.debug(\n                f\"Converted ({concept.id} | {concept.name}) to \"\n                f\"({int(vmp_id)} | {concept.name + ' ' + str(int(concept.dosage.dose.value)) + concept.dosage.dose.unit} \"\n                f\"tablets): valid extracted dosage + VMP lookup\"\n            )\n            concept.id = str(int(vmp_id))\n            concept.name += \" \" + str(int(concept.dosage.dose.value)) + str(concept.dosage.dose.unit) + \" tablets\"\n            # If found VMP match change the dosage to 1 tablet\n            concept.dosage.dose.value = 1\n            concept.dosage.dose.unit = \"{tbl}\"\n        else:\n            # If no match with dose convert to text\n            lookup_result = self.vtm_to_text_lookup.get(int(concept.id))\n            if lookup_result is not None:\n                log.debug(\n                    f\"Converted ({concept.id} | {concept.name}) to (None | {lookup_result}: no match to VMP dosage lookup)\"\n                )\n                concept.id = None\n                concept.name = lookup_result\n\n    # Convert rest of VTMs that have no dose for VMP conversion to text\n    for concept in med_concepts_no_dose:\n        lookup_result = self.vtm_to_text_lookup.get(int(concept.id))\n        if lookup_result is not None:\n            log.debug(f\"Converted ({concept.id} | {concept.name}) to (None | {lookup_result}): no dosage detected\")\n            concept.id = None\n            concept.name = lookup_result\n\n    return concepts\n</code></pre>"},{"location":"api-reference/medsallergiesannotator/#miade.annotators.MedsAllergiesAnnotator.postprocess","title":"<code>postprocess(concepts, note)</code>","text":"<p>Postprocesses a list of concepts and links reactions to allergens.</p> <p>Parameters:</p> Name Type Description Default <code>concepts</code> <code>List[Concept]</code> <p>The list of concepts to be postprocessed.</p> required <code>note</code> <code>Note</code> <p>The note object associated with the concepts.</p> required <p>Returns:</p> Type Description <code>List[Concept]</code> <p>The postprocessed list of concepts.</p> Source code in <code>miade/annotators.py</code> <pre><code>def postprocess(self, concepts: List[Concept], note: Note) -&gt; List[Concept]:\n    \"\"\"\n    Postprocesses a list of concepts and links reactions to allergens.\n\n    Args:\n        concepts (List[Concept]): The list of concepts to be postprocessed.\n        note (Note): The note object associated with the concepts.\n\n    Returns:\n       The postprocessed list of concepts.\n    \"\"\"\n    # deepcopy so we still have reference to original list of concepts\n    all_concepts = deepcopy(concepts)\n    processed_concepts = []\n\n    for concept in all_concepts:\n        concept = self._validate_and_convert_concepts(concept)\n        processed_concepts.append(concept)\n\n    processed_concepts = self._link_reactions_to_allergens(processed_concepts, note)\n\n    return processed_concepts\n</code></pre>"},{"location":"api-reference/medsallergiesannotator/#miade.annotators.MedsAllergiesAnnotator.process_paragraphs","title":"<code>process_paragraphs(note, concepts)</code>","text":"<p>Process the paragraphs in a note and update the list of concepts.</p> <p>Parameters:</p> Name Type Description Default <code>note</code> <code>Note</code> <p>The note object containing the paragraphs.</p> required <code>concepts</code> <code>List[Concept]</code> <p>The list of concepts to be updated.</p> required <p>Returns:</p> Type Description <code>List[Concept]</code> <p>The updated list of concepts.</p> Source code in <code>miade/annotators.py</code> <pre><code>def process_paragraphs(self, note: Note, concepts: List[Concept]) -&gt; List[Concept]:\n    \"\"\"\n    Process the paragraphs in a note and update the list of concepts.\n\n    Args:\n        note (Note): The note object containing the paragraphs.\n        concepts (List[Concept]): The list of concepts to be updated.\n\n    Returns:\n        The updated list of concepts.\n    \"\"\"\n    for paragraph in note.paragraphs:\n        for concept in concepts:\n            if concept.start &gt;= paragraph.start and concept.end &lt;= paragraph.end:\n                # log.debug(f\"({concept.name} | {concept.id}) is in {paragraph.type}\")\n                if concept.meta:\n                    self._process_meta_ann_by_paragraph(concept, paragraph)\n\n    return concepts\n</code></pre>"},{"location":"api-reference/medsallergiesannotator/#miade.annotators.MedsAllergiesAnnotator.run_pipeline","title":"<code>run_pipeline(note, record_concepts=None, dosage_extractor=None)</code>","text":"<p>Runs the annotation pipeline on the given note.</p> <p>Parameters:</p> Name Type Description Default <code>note</code> <code>Note</code> <p>The input note to run the pipeline on.</p> required <code>record_concepts</code> <code>Optional[List[Concept]]</code> <p>The list of previously recorded concepts.</p> <code>None</code> <code>dosage_extractor</code> <code>Optional[DosageExtractor]</code> <p>The dosage extractor function.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Concept]</code> <p>The list of annotated concepts.</p> Source code in <code>miade/annotators.py</code> <pre><code>def run_pipeline(\n    self,\n    note: Note,\n    record_concepts: Optional[List[Concept]] = None,\n    dosage_extractor: Optional[DosageExtractor] = None,\n) -&gt; List[Concept]:\n    \"\"\"\n    Runs the annotation pipeline on the given note.\n\n    Args:\n        note (Note): The input note to run the pipeline on.\n        record_concepts (Optional[List[Concept]]): The list of previously recorded concepts.\n        dosage_extractor (Optional[DosageExtractor]): The dosage extractor function.\n\n    Returns:\n        The list of annotated concepts.\n    \"\"\"\n    concepts: List[Concept] = []\n\n    for pipe in self.pipeline:\n        if pipe not in self.config.disable:\n            if pipe == \"preprocessor\":\n                note = self.preprocess(note=note)\n            elif pipe == \"medcat\":\n                concepts = self.get_concepts(note=note)\n            elif pipe == \"list_cleaner\":\n                concepts = self.filter_concepts_in_numbered_list(concepts=concepts, note=note)\n            elif pipe == \"paragrapher\":\n                concepts = self.process_paragraphs(note=note, concepts=concepts)\n            elif pipe == \"postprocessor\":\n                concepts = self.postprocess(concepts=concepts, note=note)\n            elif pipe == \"deduplicator\":\n                concepts = self.deduplicate(concepts=concepts, record_concepts=record_concepts)\n            elif pipe == \"vtm_converter\":\n                concepts = self.convert_VTM_to_VMP_or_text(concepts=concepts)\n            elif pipe == \"dosage_extractor\" and dosage_extractor is not None:\n                concepts = self.add_dosages_to_concepts(\n                    dosage_extractor=dosage_extractor, concepts=concepts, note=note\n                )\n\n    return concepts\n</code></pre>"},{"location":"api-reference/metaannotations/","title":"MetaAnnotations","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a meta annotation with a name, value, and optional confidence.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the meta annotation.</p> <code>value</code> <code>Enum</code> <p>The value of the meta annotation.</p> <code>confidence</code> <code>float</code> <p>The confidence level of the meta annotation.</p> Source code in <code>miade/metaannotations.py</code> <pre><code>class MetaAnnotations(BaseModel):\n    \"\"\"\n    Represents a meta annotation with a name, value, and optional confidence.\n\n    Attributes:\n        name (str): The name of the meta annotation.\n        value (Enum): The value of the meta annotation.\n        confidence (float, optional): The confidence level of the meta annotation.\n    \"\"\"\n\n    name: str\n    value: Enum\n    confidence: Optional[float]\n\n    @validator(\"value\", pre=True)\n    def validate_value(cls, value, values):\n        enum_dict = META_ANNS_DICT\n        if isinstance(value, str):\n            enum_type = enum_dict.get(values[\"name\"])\n            if enum_type is not None:\n                try:\n                    return enum_type(value)\n                except ValueError:\n                    raise ValueError(f\"Invalid value: {value}\")\n            else:\n                raise ValueError(f\"Invalid mapping for {values['name']}\")\n\n        return value\n\n    def __eq__(self, other):\n        return self.name == other.name and self.value == other.value\n</code></pre>"},{"location":"api-reference/note/","title":"Note","text":"<p>               Bases: <code>object</code></p> <p>Represents a Note object</p> <p>Attributes:</p> Name Type Description <code>text</code> <code>str</code> <p>The text content of the note.</p> <code>raw_text</code> <code>str</code> <p>The raw text content of the note.</p> <code>paragraphs</code> <code>Optional[List[Paragraph]]</code> <p>A list of Paragraph objects representing the paragraphs in the note.</p> <code>numbered_lists</code> <code>Optional[List[NumberedList]]</code> <p>A list of NumberedList objects representing the numbered lists in the note.</p> Source code in <code>miade/note.py</code> <pre><code>class Note(object):\n    \"\"\"\n    Represents a Note object\n\n    Attributes:\n        text (str): The text content of the note.\n        raw_text (str): The raw text content of the note.\n        paragraphs (Optional[List[Paragraph]]): A list of Paragraph objects representing the paragraphs in the note.\n        numbered_lists (Optional[List[NumberedList]]): A list of NumberedList objects representing the numbered lists in the note.\n    \"\"\"\n\n    def __init__(self, text: str):\n        self.text = text\n        self.raw_text = text\n        self.paragraphs: Optional[List[Paragraph]] = []\n        self.numbered_lists: Optional[List[NumberedList]] = []\n\n    def clean_text(self) -&gt; None:\n        \"\"\"\n        Cleans the text content of the note.\n\n        This method performs various cleaning operations on the text content of the note,\n        such as replacing spaces, removing punctuation, and removing empty lines.\n        \"\"\"\n\n        # Replace all types of spaces with a single normal space, preserving \"\\n\"\n        self.text = re.sub(r\"(?:(?!\\n)\\s)+\", \" \", self.text)\n\n        # Remove en dashes that are not between two numbers\n        self.text = re.sub(r\"(?&lt;![0-9])-(?![0-9])\", \"\", self.text)\n\n        # Remove all punctuation except full stops, question marks, dash and line breaks\n        self.text = re.sub(r\"[^\\w\\s.,?\\n-]\", \"\", self.text)\n\n        # Remove spaces if the entire line (between two line breaks) is just spaces\n        self.text = re.sub(r\"(?&lt;=\\n)\\s+(?=\\n)\", \"\", self.text)\n\n    def get_numbered_lists(self):\n        \"\"\"\n        Finds multiple lists of sequentially ordered numbers (with more than one item) that directly follow a newline character\n        and captures the text following these numbers up to the next newline.\n\n        Parameters:\n            text (str): The input text in which to search for multiple lists of sequentially ordered numbers with more than one item and their subsequent text.\n\n        Returns:\n            list of lists: Each sublist contains tuples where each tuple includes the start index of the number,\n            the end index of the line, and the captured text for each valid sequentially ordered list found. Returns an empty list if no such patterns are found.\n        \"\"\"\n        # Regular expression to find numbers followed by any characters until a newline\n        pattern = re.compile(r\"(?&lt;=\\n)(\\d+.*)\")\n\n        # Finding all matches\n        matches = pattern.finditer(self.text)\n\n        all_results = []\n        results = []\n        last_num = 0\n        for match in matches:\n            number_text = match.group(1)\n            current_num = int(re.search(r\"^\\d+\", number_text).group())\n\n            # Check if current number is the next in sequence\n            if current_num == last_num + 1:\n                results.append(ListItem(content=number_text, start=match.start(1), end=match.end(1)))\n            else:\n                # If there is a break in the sequence, check if current list has more than one item\n                if len(results) &gt; 1:\n                    numbered_list = NumberedList(items=results, list_start=results[0].start, list_end=results[-1].end)\n                    all_results.append(numbered_list)\n                results = [\n                    ListItem(content=number_text, start=match.start(1), end=match.end(1))\n                ]  # Start new results list with the current match\n            last_num = current_num  # Update last number to the current\n\n        # Add the last sequence if not empty and has more than one item\n        if len(results) &gt; 1:\n            numbered_list = NumberedList(items=results, list_start=results[0].start, list_end=results[-1].end)\n            all_results.append(numbered_list)\n\n        self.numbered_lists = all_results\n\n    def get_paragraphs(self, paragraph_regex: Dict) -&gt; None:\n        \"\"\"\n        Split the text into paragraphs and assign paragraph types based on regex patterns.\n\n        Args:\n            paragraph_regex (Dict): A dictionary containing paragraph types as keys and regex patterns as values.\n\n        Returns:\n            None\n        \"\"\"\n        paragraphs = re.split(r\"\\n\\n+\", self.text)\n        start = 0\n\n        for text in paragraphs:\n            # Default to prose\n            paragraph_type = ParagraphType.prose\n\n            # Use re.search to find everything before first \\n\n            match = re.search(r\"^(.*?)(?:\\n|$)([\\s\\S]*)\", text)\n\n            # Check if a match is found\n            if match:\n                heading = match.group(1)\n                body = match.group(2)\n            else:\n                heading = text\n                body = \"\"\n\n            end = start + len(text)\n            paragraph = Paragraph(heading=heading, body=body, type=paragraph_type, start=start, end=end)\n            start = end + 2  # Account for the two newline characters\n\n            # Convert the heading to lowercase for case-insensitive matching\n            if heading:\n                heading = heading.lower()\n                # Iterate through the dictionary items and patterns\n                for paragraph_type, pattern in paragraph_regex.items():\n                    if re.search(pattern, heading):\n                        paragraph.type = paragraph_type\n                        break  # Exit the loop if a match is found\n\n            self.paragraphs.append(paragraph)\n\n    def merge_prose_sections(self) -&gt; None:\n        \"\"\"\n        Merges consecutive prose sections in the paragraphs list.\n\n        Returns:\n            A list of merged prose sections.\n        \"\"\"\n        is_merge = False\n        all_prose = []\n        prose_section = []\n        prose_indices = []\n\n        for i, paragraph in enumerate(self.paragraphs):\n            if paragraph.type == ParagraphType.prose:\n                if is_merge:\n                    prose_section.append((i, paragraph))\n                else:\n                    prose_section = [(i, paragraph)]\n                    is_merge = True\n            else:\n                if len(prose_section) &gt; 0:\n                    all_prose.append(prose_section)\n                    prose_indices.extend([idx for idx, _ in prose_section])\n                is_merge = False\n\n        if len(prose_section) &gt; 0:\n            all_prose.append(prose_section)\n            prose_indices.extend([idx for idx, _ in prose_section])\n\n        new_paragraphs = self.paragraphs[:]\n\n        for section in all_prose:\n            start = section[0][1].start\n            end = section[-1][1].end\n            new_prose_para = Paragraph(\n                heading=self.text[start:end], body=\"\", type=ParagraphType.prose, start=start, end=end\n            )\n\n            # Replace the first paragraph in the section with the new merged paragraph\n            first_idx = section[0][0]\n            new_paragraphs[first_idx] = new_prose_para\n\n            # Mark other paragraphs in the section for deletion\n            for _, paragraph in section[1:]:\n                index = self.paragraphs.index(paragraph)\n                new_paragraphs[index] = None\n\n        # Remove the None entries from new_paragraphs\n        self.paragraphs = [para for para in new_paragraphs if para is not None]\n\n    def merge_empty_non_prose_with_next_prose(self) -&gt; None:\n        \"\"\"\n        This method checks if a Paragraph has an empty body and a type that is not prose,\n        and merges it with the next Paragraph if the next paragraph is type prose.\n\n        Returns:\n            None\n        \"\"\"\n        merged_paragraphs = []\n        skip_next = False\n\n        for i in range(len(self.paragraphs) - 1):\n            if skip_next:\n                # Skip this iteration because the previous iteration already handled merging\n                skip_next = False\n                continue\n\n            current_paragraph = self.paragraphs[i]\n            next_paragraph = self.paragraphs[i + 1]\n\n            # Check if current paragraph has an empty body and is not of type prose\n            if current_paragraph.body == \"\" and current_paragraph.type != ParagraphType.prose:\n                # Check if the next paragraph is of type prose\n                if next_paragraph.type == ParagraphType.prose:\n                    # Create a new Paragraph with merged content and type prose\n                    merged_paragraph = Paragraph(\n                        heading=current_paragraph.heading,\n                        body=next_paragraph.heading,\n                        type=current_paragraph.type,\n                        start=current_paragraph.start,\n                        end=next_paragraph.end,\n                    )\n                    merged_paragraphs.append(merged_paragraph)\n                    # Skip the next paragraph since it's already merged\n                    skip_next = True\n                    continue\n\n            # If no merging is done, add the current paragraph to the list\n            merged_paragraphs.append(current_paragraph)\n\n        # Handle the last paragraph if it wasn't merged\n        if not skip_next:\n            merged_paragraphs.append(self.paragraphs[-1])\n\n        # Update the paragraphs list with the merged paragraphs\n        self.paragraphs = merged_paragraphs\n\n    def process(self, lookup_dict: Dict, refine: bool = True):\n        \"\"\"\n        Process the note by cleaning the text, extracting numbered lists, and getting paragraphs based on a lookup dictionary.\n\n        Args:\n            lookup_dict (Dict): A dictionary used to lookup specific paragraphs.\n            refine (bool, optional): Flag indicating whether to refine the processed note - this will merge any consecutive prose\n            paragraphs and then merge any structured paragraphs with empty body with the next prose paragraph (handles line break\n            between heading and body). Defaults to True.\n        \"\"\"\n        self.clean_text()\n        self.get_numbered_lists()\n        self.get_paragraphs(lookup_dict)\n        if refine:\n            self.merge_prose_sections()\n            self.merge_empty_non_prose_with_next_prose()\n\n    def __str__(self):\n        return self.text\n</code></pre>"},{"location":"api-reference/note/#miade.note.Note.clean_text","title":"<code>clean_text()</code>","text":"<p>Cleans the text content of the note.</p> <p>This method performs various cleaning operations on the text content of the note, such as replacing spaces, removing punctuation, and removing empty lines.</p> Source code in <code>miade/note.py</code> <pre><code>def clean_text(self) -&gt; None:\n    \"\"\"\n    Cleans the text content of the note.\n\n    This method performs various cleaning operations on the text content of the note,\n    such as replacing spaces, removing punctuation, and removing empty lines.\n    \"\"\"\n\n    # Replace all types of spaces with a single normal space, preserving \"\\n\"\n    self.text = re.sub(r\"(?:(?!\\n)\\s)+\", \" \", self.text)\n\n    # Remove en dashes that are not between two numbers\n    self.text = re.sub(r\"(?&lt;![0-9])-(?![0-9])\", \"\", self.text)\n\n    # Remove all punctuation except full stops, question marks, dash and line breaks\n    self.text = re.sub(r\"[^\\w\\s.,?\\n-]\", \"\", self.text)\n\n    # Remove spaces if the entire line (between two line breaks) is just spaces\n    self.text = re.sub(r\"(?&lt;=\\n)\\s+(?=\\n)\", \"\", self.text)\n</code></pre>"},{"location":"api-reference/note/#miade.note.Note.get_numbered_lists","title":"<code>get_numbered_lists()</code>","text":"<p>Finds multiple lists of sequentially ordered numbers (with more than one item) that directly follow a newline character and captures the text following these numbers up to the next newline.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The input text in which to search for multiple lists of sequentially ordered numbers with more than one item and their subsequent text.</p> required <p>Returns:</p> Type Description <p>list of lists: Each sublist contains tuples where each tuple includes the start index of the number,</p> <p>the end index of the line, and the captured text for each valid sequentially ordered list found. Returns an empty list if no such patterns are found.</p> Source code in <code>miade/note.py</code> <pre><code>def get_numbered_lists(self):\n    \"\"\"\n    Finds multiple lists of sequentially ordered numbers (with more than one item) that directly follow a newline character\n    and captures the text following these numbers up to the next newline.\n\n    Parameters:\n        text (str): The input text in which to search for multiple lists of sequentially ordered numbers with more than one item and their subsequent text.\n\n    Returns:\n        list of lists: Each sublist contains tuples where each tuple includes the start index of the number,\n        the end index of the line, and the captured text for each valid sequentially ordered list found. Returns an empty list if no such patterns are found.\n    \"\"\"\n    # Regular expression to find numbers followed by any characters until a newline\n    pattern = re.compile(r\"(?&lt;=\\n)(\\d+.*)\")\n\n    # Finding all matches\n    matches = pattern.finditer(self.text)\n\n    all_results = []\n    results = []\n    last_num = 0\n    for match in matches:\n        number_text = match.group(1)\n        current_num = int(re.search(r\"^\\d+\", number_text).group())\n\n        # Check if current number is the next in sequence\n        if current_num == last_num + 1:\n            results.append(ListItem(content=number_text, start=match.start(1), end=match.end(1)))\n        else:\n            # If there is a break in the sequence, check if current list has more than one item\n            if len(results) &gt; 1:\n                numbered_list = NumberedList(items=results, list_start=results[0].start, list_end=results[-1].end)\n                all_results.append(numbered_list)\n            results = [\n                ListItem(content=number_text, start=match.start(1), end=match.end(1))\n            ]  # Start new results list with the current match\n        last_num = current_num  # Update last number to the current\n\n    # Add the last sequence if not empty and has more than one item\n    if len(results) &gt; 1:\n        numbered_list = NumberedList(items=results, list_start=results[0].start, list_end=results[-1].end)\n        all_results.append(numbered_list)\n\n    self.numbered_lists = all_results\n</code></pre>"},{"location":"api-reference/note/#miade.note.Note.get_paragraphs","title":"<code>get_paragraphs(paragraph_regex)</code>","text":"<p>Split the text into paragraphs and assign paragraph types based on regex patterns.</p> <p>Parameters:</p> Name Type Description Default <code>paragraph_regex</code> <code>Dict</code> <p>A dictionary containing paragraph types as keys and regex patterns as values.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>miade/note.py</code> <pre><code>def get_paragraphs(self, paragraph_regex: Dict) -&gt; None:\n    \"\"\"\n    Split the text into paragraphs and assign paragraph types based on regex patterns.\n\n    Args:\n        paragraph_regex (Dict): A dictionary containing paragraph types as keys and regex patterns as values.\n\n    Returns:\n        None\n    \"\"\"\n    paragraphs = re.split(r\"\\n\\n+\", self.text)\n    start = 0\n\n    for text in paragraphs:\n        # Default to prose\n        paragraph_type = ParagraphType.prose\n\n        # Use re.search to find everything before first \\n\n        match = re.search(r\"^(.*?)(?:\\n|$)([\\s\\S]*)\", text)\n\n        # Check if a match is found\n        if match:\n            heading = match.group(1)\n            body = match.group(2)\n        else:\n            heading = text\n            body = \"\"\n\n        end = start + len(text)\n        paragraph = Paragraph(heading=heading, body=body, type=paragraph_type, start=start, end=end)\n        start = end + 2  # Account for the two newline characters\n\n        # Convert the heading to lowercase for case-insensitive matching\n        if heading:\n            heading = heading.lower()\n            # Iterate through the dictionary items and patterns\n            for paragraph_type, pattern in paragraph_regex.items():\n                if re.search(pattern, heading):\n                    paragraph.type = paragraph_type\n                    break  # Exit the loop if a match is found\n\n        self.paragraphs.append(paragraph)\n</code></pre>"},{"location":"api-reference/note/#miade.note.Note.merge_empty_non_prose_with_next_prose","title":"<code>merge_empty_non_prose_with_next_prose()</code>","text":"<p>This method checks if a Paragraph has an empty body and a type that is not prose, and merges it with the next Paragraph if the next paragraph is type prose.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>miade/note.py</code> <pre><code>def merge_empty_non_prose_with_next_prose(self) -&gt; None:\n    \"\"\"\n    This method checks if a Paragraph has an empty body and a type that is not prose,\n    and merges it with the next Paragraph if the next paragraph is type prose.\n\n    Returns:\n        None\n    \"\"\"\n    merged_paragraphs = []\n    skip_next = False\n\n    for i in range(len(self.paragraphs) - 1):\n        if skip_next:\n            # Skip this iteration because the previous iteration already handled merging\n            skip_next = False\n            continue\n\n        current_paragraph = self.paragraphs[i]\n        next_paragraph = self.paragraphs[i + 1]\n\n        # Check if current paragraph has an empty body and is not of type prose\n        if current_paragraph.body == \"\" and current_paragraph.type != ParagraphType.prose:\n            # Check if the next paragraph is of type prose\n            if next_paragraph.type == ParagraphType.prose:\n                # Create a new Paragraph with merged content and type prose\n                merged_paragraph = Paragraph(\n                    heading=current_paragraph.heading,\n                    body=next_paragraph.heading,\n                    type=current_paragraph.type,\n                    start=current_paragraph.start,\n                    end=next_paragraph.end,\n                )\n                merged_paragraphs.append(merged_paragraph)\n                # Skip the next paragraph since it's already merged\n                skip_next = True\n                continue\n\n        # If no merging is done, add the current paragraph to the list\n        merged_paragraphs.append(current_paragraph)\n\n    # Handle the last paragraph if it wasn't merged\n    if not skip_next:\n        merged_paragraphs.append(self.paragraphs[-1])\n\n    # Update the paragraphs list with the merged paragraphs\n    self.paragraphs = merged_paragraphs\n</code></pre>"},{"location":"api-reference/note/#miade.note.Note.merge_prose_sections","title":"<code>merge_prose_sections()</code>","text":"<p>Merges consecutive prose sections in the paragraphs list.</p> <p>Returns:</p> Type Description <code>None</code> <p>A list of merged prose sections.</p> Source code in <code>miade/note.py</code> <pre><code>def merge_prose_sections(self) -&gt; None:\n    \"\"\"\n    Merges consecutive prose sections in the paragraphs list.\n\n    Returns:\n        A list of merged prose sections.\n    \"\"\"\n    is_merge = False\n    all_prose = []\n    prose_section = []\n    prose_indices = []\n\n    for i, paragraph in enumerate(self.paragraphs):\n        if paragraph.type == ParagraphType.prose:\n            if is_merge:\n                prose_section.append((i, paragraph))\n            else:\n                prose_section = [(i, paragraph)]\n                is_merge = True\n        else:\n            if len(prose_section) &gt; 0:\n                all_prose.append(prose_section)\n                prose_indices.extend([idx for idx, _ in prose_section])\n            is_merge = False\n\n    if len(prose_section) &gt; 0:\n        all_prose.append(prose_section)\n        prose_indices.extend([idx for idx, _ in prose_section])\n\n    new_paragraphs = self.paragraphs[:]\n\n    for section in all_prose:\n        start = section[0][1].start\n        end = section[-1][1].end\n        new_prose_para = Paragraph(\n            heading=self.text[start:end], body=\"\", type=ParagraphType.prose, start=start, end=end\n        )\n\n        # Replace the first paragraph in the section with the new merged paragraph\n        first_idx = section[0][0]\n        new_paragraphs[first_idx] = new_prose_para\n\n        # Mark other paragraphs in the section for deletion\n        for _, paragraph in section[1:]:\n            index = self.paragraphs.index(paragraph)\n            new_paragraphs[index] = None\n\n    # Remove the None entries from new_paragraphs\n    self.paragraphs = [para for para in new_paragraphs if para is not None]\n</code></pre>"},{"location":"api-reference/note/#miade.note.Note.process","title":"<code>process(lookup_dict, refine=True)</code>","text":"<p>Process the note by cleaning the text, extracting numbered lists, and getting paragraphs based on a lookup dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>lookup_dict</code> <code>Dict</code> <p>A dictionary used to lookup specific paragraphs.</p> required <code>refine</code> <code>bool</code> <p>Flag indicating whether to refine the processed note - this will merge any consecutive prose</p> <code>True</code> Source code in <code>miade/note.py</code> <pre><code>def process(self, lookup_dict: Dict, refine: bool = True):\n    \"\"\"\n    Process the note by cleaning the text, extracting numbered lists, and getting paragraphs based on a lookup dictionary.\n\n    Args:\n        lookup_dict (Dict): A dictionary used to lookup specific paragraphs.\n        refine (bool, optional): Flag indicating whether to refine the processed note - this will merge any consecutive prose\n        paragraphs and then merge any structured paragraphs with empty body with the next prose paragraph (handles line break\n        between heading and body). Defaults to True.\n    \"\"\"\n    self.clean_text()\n    self.get_numbered_lists()\n    self.get_paragraphs(lookup_dict)\n    if refine:\n        self.merge_prose_sections()\n        self.merge_empty_non_prose_with_next_prose()\n</code></pre>"},{"location":"api-reference/noteprocessor/","title":"NoteProcessor","text":"<p>Main processor of MiADE which extract, postprocesses, and deduplicates concepts given annotators (MedCAT models), Note, and existing concepts</p> <p>Parameters:</p> Name Type Description Default <code>model_directory</code> <code>Path</code> <p>Path to directory that contains medcat models and a config.yaml file</p> required <code>model_config_path</code> <code>Path</code> <p>Path to the model config file. Defaults to None.</p> <code>None</code> <code>log_level</code> <code>int</code> <p>Log level. Defaults to logging.INFO.</p> <code>INFO</code> <code>dosage_extractor_log_level</code> <code>int</code> <p>Log level for dosage extractor. Defaults to logging.INFO.</p> <code>INFO</code> <code>device</code> <code>str</code> <p>Device to run inference on (cpu or gpu). Defaults to \"cpu\".</p> <code>'cpu'</code> <code>custom_annotators</code> <code>List[Annotator]</code> <p>List of custom annotators. Defaults to None.</p> <code>None</code> Source code in <code>miade/core.py</code> <pre><code>class NoteProcessor:\n    \"\"\"\n    Main processor of MiADE which extract, postprocesses, and deduplicates concepts given\n    annotators (MedCAT models), Note, and existing concepts\n\n    Args:\n        model_directory (Path): Path to directory that contains medcat models and a config.yaml file\n        model_config_path (Path, optional): Path to the model config file. Defaults to None.\n        log_level (int, optional): Log level. Defaults to logging.INFO.\n        dosage_extractor_log_level (int, optional): Log level for dosage extractor. Defaults to logging.INFO.\n        device (str, optional): Device to run inference on (cpu or gpu). Defaults to \"cpu\".\n        custom_annotators (List[Annotator], optional): List of custom annotators. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_directory: Path,\n        model_config_path: Path = None,\n        log_level: int = logging.INFO,\n        dosage_extractor_log_level: int = logging.INFO,\n        device: str = \"cpu\",\n        custom_annotators: Optional[List[Annotator]] = None,\n    ):\n        logging.getLogger(\"miade\").setLevel(log_level)\n        logging.getLogger(\"miade.dosageextractor\").setLevel(dosage_extractor_log_level)\n        logging.getLogger(\"miade.drugdoseade\").setLevel(dosage_extractor_log_level)\n\n        self.device: str = device\n\n        self.annotators: List[Annotator] = []\n        self.model_directory: Path = model_directory\n        self.model_config_path: Path = model_config_path\n        self.model_factory: ModelFactory = self._load_model_factory(custom_annotators)\n        self.dosage_extractor: DosageExtractor = DosageExtractor()\n\n    def _load_config(self) -&gt; Dict:\n        \"\"\"\n        Loads the configuration file (config.yaml) in the configured model path.\n        If the model path is not explicitly passed, it defaults to the model directory.\n\n        Returns:\n            A dictionary containing the loaded config file.\n        \"\"\"\n        if self.model_config_path is None:\n            config_path = os.path.join(self.model_directory, \"config.yaml\")\n        else:\n            config_path = self.model_config_path\n\n        if os.path.isfile(config_path):\n            log.info(f\"Found config file {config_path}\")\n        else:\n            log.error(f\"No model config file found at {config_path}\")\n\n        with open(config_path, \"r\") as f:\n            config = yaml.safe_load(f)\n\n        return config\n\n    def _load_model_factory(self, custom_annotators: Optional[List[Annotator]] = None) -&gt; ModelFactory:\n        \"\"\"\n        Loads the model factory which maps model aliases to MedCAT model IDs and MiADE annotators.\n\n        Args:\n            custom_annotators (List[Annotators], optional): List of custom annotators to initialize. Defaults to None.\n\n        Returns:\n            The initialized ModelFactory object.\n\n        Raises:\n            Exception: If there is an error loading MedCAT models.\n\n        \"\"\"\n        meta_cat_config_dict = {\"general\": {\"device\": self.device}}\n        config_dict = self._load_config()\n        loaded_models = {}\n\n        # get model {id: cat_model}\n        log.info(f\"Loading MedCAT models from {self.model_directory}\")\n        for model_pack_filepath in self.model_directory.glob(\"*.zip\"):\n            try:\n                cat = MiADE_CAT.load_model_pack(str(model_pack_filepath), meta_cat_config_dict=meta_cat_config_dict)\n                # temp fix reload to load stop words\n                cat.pipe._nlp = spacy.load(\n                    cat.config.general.spacy_model, disable=cat.config.general.spacy_disabled_components\n                )\n                cat._create_pipeline(config=cat.config)\n                cat_id = cat.config.version[\"id\"]\n                loaded_models[cat_id] = cat\n            except Exception as e:\n                raise Exception(f\"Error loading MedCAT models: {e}\")\n\n        mapped_models = {}\n        # map to name if given {name: &lt;class CAT&gt;}\n        if \"models\" in config_dict:\n            for name, model_id in config_dict[\"models\"].items():\n                cat_model = loaded_models.get(model_id)\n                if cat_model is None:\n                    log.warning(f\"No match for model id {model_id} in {self.model_directory}, skipping\")\n                    continue\n                mapped_models[name] = cat_model\n        else:\n            log.warning(\"No model ids configured!\")\n\n        mapped_annotators = {}\n        # {name: &lt;class Annotator&gt;}\n        if \"annotators\" in config_dict:\n            for name, annotator_string in config_dict[\"annotators\"].items():\n                if custom_annotators is not None:\n                    for annotator_class in custom_annotators:\n                        if annotator_class.__name__ == annotator_string:\n                            mapped_annotators[name] = annotator_class\n                            break\n                if name not in mapped_annotators:\n                    try:\n                        annotator_class = getattr(sys.modules[__name__], annotator_string)\n                        mapped_annotators[name] = annotator_class\n                    except AttributeError as e:\n                        log.warning(f\"{annotator_string} not found: {e}\")\n        else:\n            log.warning(\"No annotators configured!\")\n\n        mapped_configs = {}\n        if \"general\" in config_dict:\n            for name, config in config_dict[\"general\"].items():\n                try:\n                    mapped_configs[name] = AnnotatorConfig(**config)\n                except Exception as e:\n                    log.error(f\"Error processing config for '{name}': {str(e)}\")\n        else:\n            log.warning(\"No general settings configured, using default settings.\")\n\n        model_factory_config = {\"models\": mapped_models, \"annotators\": mapped_annotators, \"configs\": mapped_configs}\n\n        return ModelFactory(**model_factory_config)\n\n    def add_annotator(self, name: str) -&gt; None:\n        \"\"\"\n        Adds an annotator to the processor.\n\n        Args:\n            name (str): The alias of the annotator to add.\n\n        Returns:\n            None\n\n        Raises:\n            Exception: If there is an error creating the annotator.\n        \"\"\"\n        try:\n            annotator = create_annotator(name, self.model_factory)\n            log.info(\n                f\"Added {type(annotator).__name__} to processor with config {self.model_factory.configs.get(name)}\"\n            )\n        except Exception as e:\n            raise Exception(f\"Error creating annotator: {e}\")\n\n        self.annotators.append(annotator)\n\n    def remove_annotator(self, name: str) -&gt; None:\n        \"\"\"\n        Removes an annotator from the processor.\n\n        Args:\n            name (str): The alias of the annotator to remove.\n\n        Returns:\n            None\n        \"\"\"\n        annotator_found = False\n        annotator_name = self.model_factory.annotators[name]\n\n        for annotator in self.annotators:\n            if type(annotator).__name__ == annotator_name.__name__:\n                self.annotators.remove(annotator)\n                annotator_found = True\n                log.info(f\"Removed {type(annotator).__name__} from processor\")\n                break\n\n        if not annotator_found:\n            log.warning(f\"Annotator {type(name).__name__} not found in processor\")\n\n    def print_model_cards(self) -&gt; None:\n        \"\"\"\n        Prints the model cards for each annotator in the `annotators` list.\n\n        Each model card includes the name of the annotator's class and its category.\n        \"\"\"\n        for annotator in self.annotators:\n            print(f\"{type(annotator).__name__}: {annotator.cat}\")\n\n    def process(self, note: Note, record_concepts: Optional[List[Concept]] = None) -&gt; List[Concept]:\n        \"\"\"\n        Process the given note and extract concepts using the loaded annotators.\n\n        Args:\n            note (Note): The note to be processed.\n            record_concepts (Optional[List[Concept]]): A list of existing concepts in the EHR record.\n\n        Returns:\n            A list of extracted concepts.\n\n        \"\"\"\n        if not self.annotators:\n            log.warning(\"No annotators loaded, use .add_annotator() to load annotators\")\n            return []\n\n        concepts: List[Concept] = []\n\n        for annotator in self.annotators:\n            log.debug(f\"Processing concepts with {type(annotator).__name__}\")\n            if Category.MEDICATION in annotator.concept_types:\n                detected_concepts = annotator(note, record_concepts, self.dosage_extractor)\n                concepts.extend(detected_concepts)\n            else:\n                detected_concepts = annotator(note, record_concepts)\n                concepts.extend(detected_concepts)\n\n        return concepts\n\n    def get_concept_dicts(\n        self, note: Note, filter_uncategorized: bool = True, record_concepts: Optional[List[Concept]] = None\n    ) -&gt; List[Dict]:\n        \"\"\"\n        Returns concepts in dictionary format.\n\n        Args:\n            note (Note): Note containing text to extract concepts from.\n            filter_uncategorized (bool): If True, does not return concepts where category=None. Default is True.\n            record_concepts (Optional[List[Concept]]): List of concepts in existing record.\n\n        Returns:\n            Extracted concepts in JSON-compatible dictionary format.\n        \"\"\"\n        concepts = self.process(note, record_concepts)\n        concept_list = []\n        for concept in concepts:\n            if filter_uncategorized and concept.category is None:\n                continue\n            concept_dict = concept.__dict__\n            if concept.dosage is not None:\n                concept_dict[\"dosage\"] = {\n                    \"dose\": concept.dosage.dose.dict() if concept.dosage.dose else None,\n                    \"duration\": concept.dosage.duration.dict() if concept.dosage.duration else None,\n                    \"frequency\": concept.dosage.frequency.dict() if concept.dosage.frequency else None,\n                    \"route\": concept.dosage.route.dict() if concept.dosage.route else None,\n                }\n            if concept.meta is not None:\n                meta_anns = []\n                for meta in concept.meta:\n                    meta_dict = meta.__dict__\n                    meta_dict[\"value\"] = meta.value.name\n                    meta_anns.append(meta_dict)\n                concept_dict[\"meta\"] = meta_anns\n            if concept.category is not None:\n                concept_dict[\"category\"] = concept.category.name\n            concept_list.append(concept_dict)\n\n        return concept_list\n</code></pre>"},{"location":"api-reference/noteprocessor/#miade.core.NoteProcessor.add_annotator","title":"<code>add_annotator(name)</code>","text":"<p>Adds an annotator to the processor.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The alias of the annotator to add.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there is an error creating the annotator.</p> Source code in <code>miade/core.py</code> <pre><code>def add_annotator(self, name: str) -&gt; None:\n    \"\"\"\n    Adds an annotator to the processor.\n\n    Args:\n        name (str): The alias of the annotator to add.\n\n    Returns:\n        None\n\n    Raises:\n        Exception: If there is an error creating the annotator.\n    \"\"\"\n    try:\n        annotator = create_annotator(name, self.model_factory)\n        log.info(\n            f\"Added {type(annotator).__name__} to processor with config {self.model_factory.configs.get(name)}\"\n        )\n    except Exception as e:\n        raise Exception(f\"Error creating annotator: {e}\")\n\n    self.annotators.append(annotator)\n</code></pre>"},{"location":"api-reference/noteprocessor/#miade.core.NoteProcessor.get_concept_dicts","title":"<code>get_concept_dicts(note, filter_uncategorized=True, record_concepts=None)</code>","text":"<p>Returns concepts in dictionary format.</p> <p>Parameters:</p> Name Type Description Default <code>note</code> <code>Note</code> <p>Note containing text to extract concepts from.</p> required <code>filter_uncategorized</code> <code>bool</code> <p>If True, does not return concepts where category=None. Default is True.</p> <code>True</code> <code>record_concepts</code> <code>Optional[List[Concept]]</code> <p>List of concepts in existing record.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>Extracted concepts in JSON-compatible dictionary format.</p> Source code in <code>miade/core.py</code> <pre><code>def get_concept_dicts(\n    self, note: Note, filter_uncategorized: bool = True, record_concepts: Optional[List[Concept]] = None\n) -&gt; List[Dict]:\n    \"\"\"\n    Returns concepts in dictionary format.\n\n    Args:\n        note (Note): Note containing text to extract concepts from.\n        filter_uncategorized (bool): If True, does not return concepts where category=None. Default is True.\n        record_concepts (Optional[List[Concept]]): List of concepts in existing record.\n\n    Returns:\n        Extracted concepts in JSON-compatible dictionary format.\n    \"\"\"\n    concepts = self.process(note, record_concepts)\n    concept_list = []\n    for concept in concepts:\n        if filter_uncategorized and concept.category is None:\n            continue\n        concept_dict = concept.__dict__\n        if concept.dosage is not None:\n            concept_dict[\"dosage\"] = {\n                \"dose\": concept.dosage.dose.dict() if concept.dosage.dose else None,\n                \"duration\": concept.dosage.duration.dict() if concept.dosage.duration else None,\n                \"frequency\": concept.dosage.frequency.dict() if concept.dosage.frequency else None,\n                \"route\": concept.dosage.route.dict() if concept.dosage.route else None,\n            }\n        if concept.meta is not None:\n            meta_anns = []\n            for meta in concept.meta:\n                meta_dict = meta.__dict__\n                meta_dict[\"value\"] = meta.value.name\n                meta_anns.append(meta_dict)\n            concept_dict[\"meta\"] = meta_anns\n        if concept.category is not None:\n            concept_dict[\"category\"] = concept.category.name\n        concept_list.append(concept_dict)\n\n    return concept_list\n</code></pre>"},{"location":"api-reference/noteprocessor/#miade.core.NoteProcessor.print_model_cards","title":"<code>print_model_cards()</code>","text":"<p>Prints the model cards for each annotator in the <code>annotators</code> list.</p> <p>Each model card includes the name of the annotator's class and its category.</p> Source code in <code>miade/core.py</code> <pre><code>def print_model_cards(self) -&gt; None:\n    \"\"\"\n    Prints the model cards for each annotator in the `annotators` list.\n\n    Each model card includes the name of the annotator's class and its category.\n    \"\"\"\n    for annotator in self.annotators:\n        print(f\"{type(annotator).__name__}: {annotator.cat}\")\n</code></pre>"},{"location":"api-reference/noteprocessor/#miade.core.NoteProcessor.process","title":"<code>process(note, record_concepts=None)</code>","text":"<p>Process the given note and extract concepts using the loaded annotators.</p> <p>Parameters:</p> Name Type Description Default <code>note</code> <code>Note</code> <p>The note to be processed.</p> required <code>record_concepts</code> <code>Optional[List[Concept]]</code> <p>A list of existing concepts in the EHR record.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Concept]</code> <p>A list of extracted concepts.</p> Source code in <code>miade/core.py</code> <pre><code>def process(self, note: Note, record_concepts: Optional[List[Concept]] = None) -&gt; List[Concept]:\n    \"\"\"\n    Process the given note and extract concepts using the loaded annotators.\n\n    Args:\n        note (Note): The note to be processed.\n        record_concepts (Optional[List[Concept]]): A list of existing concepts in the EHR record.\n\n    Returns:\n        A list of extracted concepts.\n\n    \"\"\"\n    if not self.annotators:\n        log.warning(\"No annotators loaded, use .add_annotator() to load annotators\")\n        return []\n\n    concepts: List[Concept] = []\n\n    for annotator in self.annotators:\n        log.debug(f\"Processing concepts with {type(annotator).__name__}\")\n        if Category.MEDICATION in annotator.concept_types:\n            detected_concepts = annotator(note, record_concepts, self.dosage_extractor)\n            concepts.extend(detected_concepts)\n        else:\n            detected_concepts = annotator(note, record_concepts)\n            concepts.extend(detected_concepts)\n\n    return concepts\n</code></pre>"},{"location":"api-reference/noteprocessor/#miade.core.NoteProcessor.remove_annotator","title":"<code>remove_annotator(name)</code>","text":"<p>Removes an annotator from the processor.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The alias of the annotator to remove.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>miade/core.py</code> <pre><code>def remove_annotator(self, name: str) -&gt; None:\n    \"\"\"\n    Removes an annotator from the processor.\n\n    Args:\n        name (str): The alias of the annotator to remove.\n\n    Returns:\n        None\n    \"\"\"\n    annotator_found = False\n    annotator_name = self.model_factory.annotators[name]\n\n    for annotator in self.annotators:\n        if type(annotator).__name__ == annotator_name.__name__:\n            self.annotators.remove(annotator)\n            annotator_found = True\n            log.info(f\"Removed {type(annotator).__name__} from processor\")\n            break\n\n    if not annotator_found:\n        log.warning(f\"Annotator {type(name).__name__} not found in processor\")\n</code></pre>"},{"location":"api-reference/problemsannotator/","title":"ProblemsAnnotator","text":"<p>               Bases: <code>Annotator</code></p> <p>Annotator class for identifying and processing problems in medical notes.</p> <p>This class extends the base <code>Annotator</code> class and provides specific functionality for identifying and processing problems in medical notes. It implements methods for loading problem lookup data, processing meta annotations, filtering concepts, and post-processing the annotated concepts.</p> <p>Attributes:</p> Name Type Description <code>cat</code> <code>CAT</code> <p>The CAT (Concept Annotation Tool) instance used for annotation.</p> <code>config</code> <code>AnnotatorConfig</code> <p>The configuration object for the annotator.</p> Properties <p>concept_types (list): A list of concept types supported by this annotator. pipeline (list): The list of processing steps in the annotation pipeline.</p> Source code in <code>miade/annotators.py</code> <pre><code>class ProblemsAnnotator(Annotator):\n    \"\"\"\n    Annotator class for identifying and processing problems in medical notes.\n\n    This class extends the base `Annotator` class and provides specific functionality\n    for identifying and processing problems in medical notes. It implements methods\n    for loading problem lookup data, processing meta annotations, filtering concepts,\n    and post-processing the annotated concepts.\n\n    Attributes:\n        cat (CAT): The CAT (Concept Annotation Tool) instance used for annotation.\n        config (AnnotatorConfig): The configuration object for the annotator.\n\n    Properties:\n        concept_types (list): A list of concept types supported by this annotator.\n        pipeline (list): The list of processing steps in the annotation pipeline.\n    \"\"\"\n\n    def __init__(self, cat: CAT, config: AnnotatorConfig = None):\n        super().__init__(cat, config)\n        self._load_problems_lookup_data()\n\n    @property\n    def concept_types(self) -&gt; List[Category]:\n        \"\"\"\n        Get the list of concept types supported by this annotator.\n\n        Returns:\n            [Category.PROBLEM]\n        \"\"\"\n        return [Category.PROBLEM]\n\n    @property\n    def pipeline(self) -&gt; List[str]:\n        \"\"\"\n        Get the list of processing steps in the annotation pipeline.\n\n        Returns:\n            [\"preprocessor\", \"medcat\", \"list_cleaner\", \"paragrapher\", \"postprocessor\", \"deduplicator\"]\n        \"\"\"\n        return [\"preprocessor\", \"medcat\", \"list_cleaner\", \"paragrapher\", \"postprocessor\", \"deduplicator\"]\n\n    def run_pipeline(self, note: Note, record_concepts: Optional[List[Concept]] = None) -&gt; List[Concept]:\n        \"\"\"\n        Runs the annotation pipeline on a given note and returns the extracted problems concepts.\n\n        Args:\n            note (Note): The input note to process.\n            record_concepts (Optional[List[Concept]]): The list of concepts from existing EHR records.\n\n        Returns:\n            List[Concept]: The extracted concepts from the note.\n        \"\"\"\n        # TODO: not the best way to do this - make this more extensible!!\n        concepts: List[Concept] = []\n\n        for pipe in self.pipeline:\n            if pipe not in self.config.disable:\n                if pipe == \"preprocessor\":\n                    note = self.preprocess(note=note, refine=self.config.refine_paragraphs)\n                elif pipe == \"medcat\":\n                    concepts = self.get_concepts(note=note)\n                elif pipe == \"list_cleaner\":\n                    concepts = self.filter_concepts_in_numbered_list(concepts=concepts, note=note)\n                elif pipe == \"paragrapher\":\n                    concepts = self.process_paragraphs(note=note, concepts=concepts)\n                elif pipe == \"postprocessor\":\n                    concepts = self.postprocess(concepts=concepts)\n                elif pipe == \"deduplicator\":\n                    concepts = self.deduplicate(concepts=concepts, record_concepts=record_concepts)\n\n        return concepts\n\n    def _load_problems_lookup_data(self) -&gt; None:\n        \"\"\"\n        Load the problem lookup data. Load prepackaged lookups if lookup_data_path is None.\n\n        Raises:\n            RuntimeError: If the lookup data directory does not exist.\n        \"\"\"\n        self.negated_lookup = load_lookup_data(\n            self.lookup_data_path + \"negated.csv\", is_package_data=self.use_package_data, as_dict=True\n        )\n        self.historic_lookup = load_lookup_data(\n            self.lookup_data_path + \"historic.csv\", is_package_data=self.use_package_data, as_dict=True\n        )\n        self.suspected_lookup = load_lookup_data(\n            self.lookup_data_path + \"suspected.csv\", is_package_data=self.use_package_data, as_dict=True\n        )\n        self.filtering_blacklist = load_lookup_data(\n            self.lookup_data_path + \"problem_blacklist.csv\", is_package_data=self.use_package_data, no_header=True\n        )\n\n    def _process_meta_annotations(self, concept: Concept) -&gt; Optional[Concept]:\n        \"\"\"\n        Process the meta annotations for a concept.\n\n        Args:\n            concept (Concept): The concept to process.\n\n        Returns:\n           The processed concept, or None if it should be removed.\n\n        Raises:\n            ValueError: If the concept has an invalid negex value.\n        \"\"\"\n        # Add, convert, or ignore concepts\n        meta_ann_values = [meta_ann.value for meta_ann in concept.meta] if concept.meta is not None else []\n\n        convert = False\n        tag = \"\"\n        # only get meta model results if negex is false\n        if concept.negex is not None:\n            if concept.negex:\n                convert = self.negated_lookup.get(int(concept.id), False)\n                tag = \" (negated)\"\n            elif Presence.SUSPECTED in meta_ann_values:\n                convert = self.suspected_lookup.get(int(concept.id), False)\n                tag = \" (suspected)\"\n            elif Relevance.HISTORIC in meta_ann_values:\n                convert = self.historic_lookup.get(int(concept.id), False)\n                tag = \" (historic)\"\n        else:\n            if Presence.NEGATED in meta_ann_values:\n                convert = self.negated_lookup.get(int(concept.id), False)\n                tag = \" (negated)\"\n            elif Presence.SUSPECTED in meta_ann_values:\n                convert = self.suspected_lookup.get(int(concept.id), False)\n                tag = \" (suspected)\"\n            elif Relevance.HISTORIC in meta_ann_values:\n                convert = self.historic_lookup.get(int(concept.id), False)\n                tag = \" (historic)\"\n\n        if convert:\n            if tag == \" (negated)\" and concept.negex:\n                log.debug(\n                    f\"Converted concept ({concept.id} | {concept.name}) to ({str(convert)} | {concept.name + tag}): \"\n                    f\"negation detected by negex\"\n                )\n            else:\n                log.debug(\n                    f\"Converted concept ({concept.id} | {concept.name}) to ({str(convert)} | {concept.name + tag}):\"\n                    f\"detected by meta model\"\n                )\n            concept.id = str(convert)\n            concept.name += tag\n        else:\n            if concept.negex:\n                log.debug(f\"Removed concept ({concept.id} | {concept.name}): negation (negex) with no conversion match\")\n                return None\n            if concept.negex is None and Presence.NEGATED in meta_ann_values:\n                log.debug(\n                    f\"Removed concept ({concept.id} | {concept.name}): negation (meta model) with no conversion match\"\n                )\n                return None\n            if Presence.SUSPECTED in meta_ann_values:\n                log.debug(f\"Removed concept ({concept.id} | {concept.name}): suspected with no conversion match\")\n                return None\n            if Relevance.IRRELEVANT in meta_ann_values:\n                log.debug(f\"Removed concept ({concept.id} | {concept.name}): irrelevant concept\")\n                return None\n            if Relevance.HISTORIC in meta_ann_values:\n                log.debug(f\"No change to concept ({concept.id} | {concept.name}): historic with no conversion match\")\n\n        concept.category = Category.PROBLEM\n\n        return concept\n\n    def _is_blacklist(self, concept):\n        \"\"\"\n        Check if a concept is in the filtering blacklist.\n\n        Args:\n            concept: The concept to check.\n\n        Returns:\n            True if the concept is in the blacklist, False otherwise.\n        \"\"\"\n        # filtering blacklist\n        if int(concept.id) in self.filtering_blacklist.values:\n            log.debug(f\"Removed concept ({concept.id} | {concept.name}): concept in problems blacklist\")\n            return True\n        return False\n\n    def _process_meta_ann_by_paragraph(\n        self, concept: Concept, paragraph: Paragraph, prob_concepts_in_structured_sections: List[Concept]\n    ):\n        \"\"\"\n        Process the meta annotations for a concept based on the paragraph type.\n\n        Args:\n            concept (Concept): The concept to process.\n            paragraph (Paragraph): The paragraph containing the concept.\n            prob_concepts_in_structured_sections (List[Concept]): The list of problem concepts in structured sections.\n        \"\"\"\n        # if paragraph is structured problems section, add to prob list and convert to corresponding relevance\n        if paragraph.type in self.structured_prob_lists:\n            prob_concepts_in_structured_sections.append(concept)\n            for meta in concept.meta:\n                if meta.name == \"relevance\" and meta.value == Relevance.IRRELEVANT:\n                    new_relevance = self.structured_prob_lists[paragraph.type]\n                    log.debug(\n                        f\"Converted {meta.value} to \"\n                        f\"{new_relevance} for concept ({concept.id} | {concept.name}): \"\n                        f\"paragraph is {paragraph.type}\"\n                    )\n                    meta.value = new_relevance\n        # if paragraph is meds or irrelevant section, convert problems to irrelevant\n        elif paragraph.type in self.structured_med_lists or paragraph.type in self.irrelevant_paragraphs:\n            for meta in concept.meta:\n                if meta.name == \"relevance\" and meta.value != Relevance.IRRELEVANT:\n                    log.debug(\n                        f\"Converted {meta.value} to \"\n                        f\"{Relevance.IRRELEVANT} for concept ({concept.id} | {concept.name}): \"\n                        f\"paragraph is {paragraph.type}\"\n                    )\n                    meta.value = Relevance.IRRELEVANT\n\n    def process_paragraphs(self, note: Note, concepts: List[Concept]) -&gt; List[Concept]:\n        \"\"\"\n        Process the paragraphs in a note and filter the concepts.\n\n        Args:\n            note (Note): The note to process.\n            concepts (List[Concept]): The list of concepts to filter.\n\n        Returns:\n            The filtered list of concepts.\n        \"\"\"\n        prob_concepts_in_structured_sections: List[Concept] = []\n        if note.paragraphs:\n            # Use a list comprehension to flatten the loop and conditionals\n            concepts_in_paragraphs = [\n                (concept, paragraph)\n                for paragraph in note.paragraphs\n                for concept in concepts\n                if concept.start &gt;= paragraph.start and concept.end &lt;= paragraph.end and concept.meta\n            ]\n            # Process each concept and paragraph pair\n            for concept, paragraph in concepts_in_paragraphs:\n                self._process_meta_ann_by_paragraph(concept, paragraph, prob_concepts_in_structured_sections)\n        else:\n            log.warn(\"Unable to run paragrapher pipeline: did you add preprocessor to the pipeline?\")\n\n        # if more than set no. concepts in prob or imp or pmh sections, return only those and ignore all other concepts\n        if len(prob_concepts_in_structured_sections) &gt; self.config.structured_list_limit:\n            log.debug(\n                f\"Ignoring concepts elsewhere in the document because \"\n                f\"more than {self.config.structured_list_limit} concepts exist \"\n                f\"in prob, imp, pmh structured sections: {len(prob_concepts_in_structured_sections)}\"\n            )\n            return prob_concepts_in_structured_sections\n\n        return concepts\n\n    def postprocess(self, concepts: List[Concept]) -&gt; List[Concept]:\n        \"\"\"\n        Post-process the concepts and filter out irrelevant concepts.\n\n        Args:\n            concepts (List[Concept]): The list of concepts to post-process.\n\n        Returns:\n            The filtered list of concepts.\n        \"\"\"\n        # deepcopy so we still have reference to original list of concepts\n        all_concepts = deepcopy(concepts)\n        filtered_concepts = []\n        for concept in all_concepts:\n            if self._is_blacklist(concept):\n                continue\n            # meta annotations\n            concept = self._process_meta_annotations(concept)\n            # ignore concepts filtered by meta-annotations\n            if concept is None:\n                continue\n            filtered_concepts.append(concept)\n\n        return filtered_concepts\n</code></pre>"},{"location":"api-reference/problemsannotator/#miade.annotators.ProblemsAnnotator.concept_types","title":"<code>concept_types</code>  <code>property</code>","text":"<p>Get the list of concept types supported by this annotator.</p> <p>Returns:</p> Type Description <code>List[Category]</code> <p>[Category.PROBLEM]</p>"},{"location":"api-reference/problemsannotator/#miade.annotators.ProblemsAnnotator.pipeline","title":"<code>pipeline</code>  <code>property</code>","text":"<p>Get the list of processing steps in the annotation pipeline.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>[\"preprocessor\", \"medcat\", \"list_cleaner\", \"paragrapher\", \"postprocessor\", \"deduplicator\"]</p>"},{"location":"api-reference/problemsannotator/#miade.annotators.ProblemsAnnotator.postprocess","title":"<code>postprocess(concepts)</code>","text":"<p>Post-process the concepts and filter out irrelevant concepts.</p> <p>Parameters:</p> Name Type Description Default <code>concepts</code> <code>List[Concept]</code> <p>The list of concepts to post-process.</p> required <p>Returns:</p> Type Description <code>List[Concept]</code> <p>The filtered list of concepts.</p> Source code in <code>miade/annotators.py</code> <pre><code>def postprocess(self, concepts: List[Concept]) -&gt; List[Concept]:\n    \"\"\"\n    Post-process the concepts and filter out irrelevant concepts.\n\n    Args:\n        concepts (List[Concept]): The list of concepts to post-process.\n\n    Returns:\n        The filtered list of concepts.\n    \"\"\"\n    # deepcopy so we still have reference to original list of concepts\n    all_concepts = deepcopy(concepts)\n    filtered_concepts = []\n    for concept in all_concepts:\n        if self._is_blacklist(concept):\n            continue\n        # meta annotations\n        concept = self._process_meta_annotations(concept)\n        # ignore concepts filtered by meta-annotations\n        if concept is None:\n            continue\n        filtered_concepts.append(concept)\n\n    return filtered_concepts\n</code></pre>"},{"location":"api-reference/problemsannotator/#miade.annotators.ProblemsAnnotator.process_paragraphs","title":"<code>process_paragraphs(note, concepts)</code>","text":"<p>Process the paragraphs in a note and filter the concepts.</p> <p>Parameters:</p> Name Type Description Default <code>note</code> <code>Note</code> <p>The note to process.</p> required <code>concepts</code> <code>List[Concept]</code> <p>The list of concepts to filter.</p> required <p>Returns:</p> Type Description <code>List[Concept]</code> <p>The filtered list of concepts.</p> Source code in <code>miade/annotators.py</code> <pre><code>def process_paragraphs(self, note: Note, concepts: List[Concept]) -&gt; List[Concept]:\n    \"\"\"\n    Process the paragraphs in a note and filter the concepts.\n\n    Args:\n        note (Note): The note to process.\n        concepts (List[Concept]): The list of concepts to filter.\n\n    Returns:\n        The filtered list of concepts.\n    \"\"\"\n    prob_concepts_in_structured_sections: List[Concept] = []\n    if note.paragraphs:\n        # Use a list comprehension to flatten the loop and conditionals\n        concepts_in_paragraphs = [\n            (concept, paragraph)\n            for paragraph in note.paragraphs\n            for concept in concepts\n            if concept.start &gt;= paragraph.start and concept.end &lt;= paragraph.end and concept.meta\n        ]\n        # Process each concept and paragraph pair\n        for concept, paragraph in concepts_in_paragraphs:\n            self._process_meta_ann_by_paragraph(concept, paragraph, prob_concepts_in_structured_sections)\n    else:\n        log.warn(\"Unable to run paragrapher pipeline: did you add preprocessor to the pipeline?\")\n\n    # if more than set no. concepts in prob or imp or pmh sections, return only those and ignore all other concepts\n    if len(prob_concepts_in_structured_sections) &gt; self.config.structured_list_limit:\n        log.debug(\n            f\"Ignoring concepts elsewhere in the document because \"\n            f\"more than {self.config.structured_list_limit} concepts exist \"\n            f\"in prob, imp, pmh structured sections: {len(prob_concepts_in_structured_sections)}\"\n        )\n        return prob_concepts_in_structured_sections\n\n    return concepts\n</code></pre>"},{"location":"api-reference/problemsannotator/#miade.annotators.ProblemsAnnotator.run_pipeline","title":"<code>run_pipeline(note, record_concepts=None)</code>","text":"<p>Runs the annotation pipeline on a given note and returns the extracted problems concepts.</p> <p>Parameters:</p> Name Type Description Default <code>note</code> <code>Note</code> <p>The input note to process.</p> required <code>record_concepts</code> <code>Optional[List[Concept]]</code> <p>The list of concepts from existing EHR records.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Concept]</code> <p>List[Concept]: The extracted concepts from the note.</p> Source code in <code>miade/annotators.py</code> <pre><code>def run_pipeline(self, note: Note, record_concepts: Optional[List[Concept]] = None) -&gt; List[Concept]:\n    \"\"\"\n    Runs the annotation pipeline on a given note and returns the extracted problems concepts.\n\n    Args:\n        note (Note): The input note to process.\n        record_concepts (Optional[List[Concept]]): The list of concepts from existing EHR records.\n\n    Returns:\n        List[Concept]: The extracted concepts from the note.\n    \"\"\"\n    # TODO: not the best way to do this - make this more extensible!!\n    concepts: List[Concept] = []\n\n    for pipe in self.pipeline:\n        if pipe not in self.config.disable:\n            if pipe == \"preprocessor\":\n                note = self.preprocess(note=note, refine=self.config.refine_paragraphs)\n            elif pipe == \"medcat\":\n                concepts = self.get_concepts(note=note)\n            elif pipe == \"list_cleaner\":\n                concepts = self.filter_concepts_in_numbered_list(concepts=concepts, note=note)\n            elif pipe == \"paragrapher\":\n                concepts = self.process_paragraphs(note=note, concepts=concepts)\n            elif pipe == \"postprocessor\":\n                concepts = self.postprocess(concepts=concepts)\n            elif pipe == \"deduplicator\":\n                concepts = self.deduplicate(concepts=concepts, record_concepts=record_concepts)\n\n    return concepts\n</code></pre>"},{"location":"user-guide/configurations/","title":"Configurations","text":""},{"location":"user-guide/configurations/#annotator","title":"Annotator","text":"<p>The MiADE processor is configured by a <code>yaml</code> file that maps a human-readable key for each of your models to a MedCAT model ID and an MiADE <code>Annotator</code>. The config file must be in the same folder as the MedCAT models.</p> <p>Required</p> <ul> <li><code>models</code>: The models section maps human-readable key-value pairing to the MedCAT model ID to use in MiADE</li> <li><code>annotators</code>: The annotators section maps human-readable key-value pairing to <code>Annotator</code> processing classes to use in MiADE</li> </ul> <p>Optional</p> <ul> <li><code>lookup_data_path</code>: Specifies the lookup data to use. If <code>None</code> a default MiADE set will be used.</li> <li><code>negation_detection</code>: <code>negex</code> (default rule-based algorithm) or <code>None</code> (use MetaCAT models)</li> <li><code>structured_list_limit</code>: Specifies the maximum number of concepts detected in a structured paragraph section. If there are more than the set number of concepts in a structured list, then concepts detected in prose are ignored (prioritises concepts detected in structured lists over free-form text to avoid returning too many irrelevant concepts). Default <code>100</code> so this feature is essentially disabled.</li> <li><code>disable</code>: Disable any specific postprocessing pipeline components - the usage here is similar to spaCy pipelines.</li> <li><code>add_numbering</code>: Option to add a number prefix to the concept display names e.g. \"01 Diabetes\"</li> </ul> <p>config.yaml<pre><code>models:\n  problems: f25ec9423958e8d6\n  meds/allergies: a146c741501cf1f7\nannotators:\n  problems: ProblemsAnnotator\n  meds/allergies: MedsAllergiesAnnotator\ngeneral:\n  problems:\n    lookup_data_path: ./custom_lookup_data/\n    structured_list_limit: 0  # setting as 0 will ignore all concepts found in prose\n    add_numbering: True\n  meds/allergies:\n    disable: [\"vtm_converter\"]\n</code></pre> The default configurations for annotators are defined below:</p> <p>               Bases: <code>BaseModel</code></p> Source code in <code>miade/utils/annotatorconfig.py</code> <pre><code>class AnnotatorConfig(BaseModel):\n    lookup_data_path: Optional[str] = None\n    negation_detection: Optional[str] = \"negex\"\n    structured_list_limit: Optional[int] = 100\n    refine_paragraphs: Optional[bool] = True\n    disable: List[str] = []\n    add_numbering: bool = False\n</code></pre>"},{"location":"user-guide/configurations/#lookup-table","title":"Lookup Table","text":"<p>Lookup tables are used to convert and filter concepts in the MiADE postprocessing steps for <code>ProblemsAnnotator</code> and <code>MedsAllergiesAnnotator</code>. We have packaged default lookup data (curated and used at UCLH) with MiADE for sample use. </p> <p>For a more detailed explanation on the creation and format of the lookup data, check out miade-dataset.</p> <p>To customise your own lookup tables, you can pass in a directory which contains your lookup data in the <code>config.yaml</code> <code>lookup_data_path</code> field. Note you currently need to have ALL of the required lookup data in your directory (this will be improved in the future).</p> <p>Problems <pre><code>negated.csv\nhistoric.csv\nsuspected.csv\nproblem_blacklist.csv\n</code></pre></p> <p>MedsAllergies <pre><code>reactions_subset.csv\nallergens_subset.csv\nallergy_type.csv\nvalid_meds.csv\nvtm_to_text.csv\nvtm_to_vmp.csv\n</code></pre></p>"},{"location":"user-guide/cookbook/","title":"Cookbook","text":"<p>Coming soon!</p>"},{"location":"user-guide/quickstart/","title":"Quickstart","text":""},{"location":"user-guide/quickstart/#extract-concepts-and-dosages-from-a-note-using-miade","title":"Extract concepts and dosages from a Note using MiADE","text":""},{"location":"user-guide/quickstart/#configuring-the-miade-processor","title":"Configuring the MiADE Processor","text":"<p><code>NoteProcessor</code> is the MiADE core. It is initialised with a model directory path that contains all the MedCAT model pack <code>.zip</code> files we would like to use in our pipeline, and a <code>config.yaml</code> file that maps an alias to the model IDs and annotators we would like to use (model IDs can be found in MedCAT <code>model_cards</code> or usually will be in the name).</p> <p>An example project structure may look like this: <pre><code>your_project/\n\u251c\u2500\u2500 model_directory/\n\u2502   \u251c\u2500\u2500 medcat_problems_modelpack_f25ec9423958e8d6.zip\n\u2502   \u251c\u2500\u2500 medcat_meds_modelpack_a146c741501cf1f7.zip\n\u2502   \u2514\u2500\u2500 config.yaml\n\u2514\u2500\u2500 miade_driver_code.py\n</code></pre></p> <p>config.yaml<pre><code>models:\n  problems: f25ec9423958e8d6\n  meds/allergies: a146c741501cf1f7\nannotators:\n  problems: ProblemsAnnotator\n  meds/allergies: MedsAllergiesAnnotator\n</code></pre> We can initialise the MiADE <code>NoteProcessor</code> by passing in the model directory which contains our MedCAT models and <code>config.yaml</code> file:</p> <p><pre><code>miade = NoteProcessor(Path(\"path/to/model/dir\"))\n</code></pre> Once <code>NoteProcessor</code> is initialised, we can add annotators by the aliases we have specified in <code>config.yaml</code> to our processor. Each annotator wraps around a MedCAT model and performs additional postprocessing pipeline steps:</p> <p><pre><code>miade.add_annotator(\"problems\")\nmiade.add_annotator(\"meds/allergies\")\n</code></pre> By default annotators will add negSpacy to MedCAT, which implements the negEx algorithm (Chapman et al. 2001) for negation detection. This allows the models to perform simple rule-based negation detection in the absence of trained MetaCAT models. You can disable this in the configurations if you wish to use your own MetaCAT instead.</p>"},{"location":"user-guide/quickstart/#creating-a-note","title":"Creating a Note","text":"<p>Create a <code>Note</code> object which contains the text we would like to extract concepts and dosages from:</p> <pre><code>text = \"\"\"\nSuspected heart failure\n\nPMH:\nprev history of Hypothyroidism\nMI 10 years ago\n\n\nCurrent meds:\nLosartan 100mg daily\nAtorvastatin 20mg daily\nParacetamol 500mg tablets 2 tabs qds prn\n\nAllergies:\nPenicillin - rash\n\nReferred with swollen ankles and shortness of breath since 2 weeks.\n\"\"\"\n\nnote = Note(text)\n</code></pre>"},{"location":"user-guide/quickstart/#extracting-concepts-and-dosages","title":"Extracting Concepts and Dosages","text":"<p>MiADE can extract concepts in any code system you train your MedCAT models on. Each concept is code system-agnostic and contains:</p> <ul> <li><code>name</code>: name of concept</li> <li><code>id</code>: concept ID</li> <li><code>category</code>: type of concept e.g. problems, medictions</li> <li><code>start</code>: start index of concept span</li> <li><code>end</code>: end index of concept span</li> <li><code>dosage</code>: for medication concepts</li> <li><code>negex</code>: Negex result if configured</li> <li><code>meta</code>: Meta annotations if MetaCAT models are used</li> </ul> <p>The dosages associated with medication concepts are extracted by the built-in MiADE <code>DosageExtractor</code>, using a combination of NER model med7 and CALIBER rule-based drug dose lookup algorithm. It returns the dosage information in a format that is can be easily translated to HL7 standards such as CDA and FHIR:</p> <ul> <li><code>dose</code></li> <li><code>duration</code></li> <li><code>frequency</code></li> <li><code>route</code></li> </ul> <p>Putting it all together, we can now extract concepts from our <code>Note</code> object:</p> as Concept objectas Dict <pre><code>concepts = miade.process(note)\nfor concept in concepts:\n    print(concept)\n\n# SNOMED CT codes\n# {name: breaking out - eruption, id: 271807003, category: Category.REACTION, start: 204, end: 208, dosage: None, negex: False, meta: None} \n# {name: penicillin, id: 764146007, category: Category.ALLERGY, start: 191, end: 201, dosage: None, negex: False, meta: None} \n</code></pre> <pre><code>concepts = miade.get_concept_dicts(note)\nprint(concepts)\n\n# [{'name': 'hypothyroidism (historic)',\n# 'id': '161443002',\n# 'category': 'PROBLEM',\n# 'start': 46,\n# 'end': 60,\n# 'dosage': None,\n# 'negex': False,\n# 'meta': [{'name': 'relevance',\n#           'value': 'HISTORIC',\n#           'confidence': 0.999841570854187},\n# ...\n</code></pre>"},{"location":"user-guide/quickstart/#handling-existing-records-deduplication","title":"Handling existing records: deduplication","text":"<p>MiADE is built to handle existing medication records from EHR systems that can be sent alongside the note. It will perform basic deduplication matching on IDs for existing record concepts. <pre><code># create list of concepts that already exists in patient record\nrecord_concepts = [\n    Concept(id=\"161443002\", name=\"hypothyroidism (historic)\", category=Category.PROBLEM),\n    Concept(id=\"267039000\", name=\"swollen ankle\", category=Category.PROBLEM)\n]\n</code></pre></p> <p>We can pass in a list of existing concepts from the EHR to MiADE at runtime:</p> <pre><code>miade.process(note=note, record_concepts=record_concepts)\n</code></pre>"},{"location":"user-guide/quickstart/#customising-miade","title":"Customising MiADE","text":""},{"location":"user-guide/quickstart/#training-custom-medcat-models","title":"Training Custom MedCAT Models","text":"<p>MiADE provides command line interface scripts for automatically building MedCAT model packs. This includes the unsupervised training and supervised training steps of MedCAT models, and the training and packaging of MetaCAT models, which perform additional context detection using a Bi-LSTM model. For more information on MedCAT models, see MedCAT documentation and paper.</p> <p>The <code>--synthetic-data-path</code> option allows you to add synthetically generated training data in CSV format to the supervised and MetaCAT training steps. The CSV should have the following format:</p> text cui name start end relevance presence laterality no history of liver failure 59927004 hepatic failure 14 26 historic negated none <p><pre><code># Trains unsupervised training step of MedCAT model\nmiade train $MODEL_PACK_PATH $TEXT_DATA_PATH --tag \"miade-example\"\n</code></pre> <pre><code># Trains supervised training step of MedCAT model\nmiade train-supervised $MODEL_PACK_PATH $MEDCAT_JSON_EXPORT --synthetic-data-path $SYNTHETIC_CSV_PATH\n</code></pre> <pre><code># Creates BBPE tokenizer for MetaCAT\nmiade create-bbpe-tokenizer $TEXT_DATA_PATH\n</code></pre> <pre><code># Initialises MetaCAT models to do training on\nmiade create-metacats $TOKENIZER_PATH $CATEGORY_NAMES\n</code></pre> <pre><code># Trains the MetaCAT Bi-LSTM models\nmiade train-metacats $METACAT_MODEL_PATH $MEDCAT_JSON_EXPORT --synthetic-data-path $SYNTHETIC_CSV_PATH\n</code></pre> <pre><code># Packages MetaCAT models with the main MedCAT model pack\nmiade add_metacat_models $MODEL_PACK_PATH $METACAT_MODEL_PATH\n</code></pre></p>"},{"location":"user-guide/quickstart/#creating-custom-miade-annotators","title":"Creating Custom MiADE Annotators","text":"<p>We can add custom annotators with more specialised postprocessing steps to MiADE by subclassing <code>Annotator</code> and initialising <code>NoteProcessor</code> with a list of custom annotators.</p> <p>Built-in <code>Annotator</code> pipeline methods include:</p> <ul> <li><code>\"preprocess\"</code>: performs basic text cleaning and structural information on the note</li> <li><code>\"medcat\"</code>: returns MedCAT output as MiADE <code>Concepts</code></li> <li><code>\"dosage_extractor\"</code>: uses the MiADE built-in <code>DosageExtractor</code> to add dosages associated with medication concepts</li> <li><code>\"deduplicator\"</code>: filters duplicate concepts in list </li> </ul> <p>You must specify the type of concepts your custom annotator returns (see Category), a pipeline processing order, and implement a <code>postprocess()</code> function. An example custom <code>Annotator</code> class might look like this:</p> <pre><code>class CustomAnnotator(Annotator):\n    def __init__(self, cat: MiADE_CAT):\n        super().__init__(cat)\n        self.reactions = [\"271807003\"]\n        self.allergens = [\"764146007\"]\n\n    @property\n    def concept_types(self) -&gt; List[Category]:\n        return [Category.MEDICATION, Category.ALLERGY]\n\n    @property\n    def pipeline(self) -&gt; List[str]:\n        return [\"preprocessor\", \"medcat\", \"postprocessor\", \"dosage_extractor\", \"deduplicator\"]\n\n    def postprocess(self, concepts: List[Concept]) -&gt; List[Concept]:\n        # some example post-processing code\n        for concept in concepts:\n            if concept.id in self.reactions:\n                concept.category = Category.REACTION\n            elif concept.id in self.allergens:\n                concept.category = Category.ALLERGY\n        return concepts\n</code></pre> <p>Add the custom annotator to config file:</p> config.yaml<pre><code>models:\n  problems: f25ec9423958e8d6\n  meds/allergies: a146c741501cf1f7\n  custom: a146c741501cf1f7\nannotators:\n  problems: ProblemsAnnotator\n  meds/allergies: MedsAllergiesAnnotator\n  custom: CustomAnnotator\n</code></pre> <p>Initialise MiADE with the custom annotator:</p> <pre><code>miade = NoteProcessor(Path(\"path/to/model/dir\"), custom_annotators=[CustomAnnotator])\nmiade.add_annotator(\"custom\")\n</code></pre>"},{"location":"user-guide/quickstart/#going-further","title":"Going further","text":"<p>Check out our cookbook!</p>"}]}