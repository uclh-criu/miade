#!/usr/bin/env python
import os
import json
import logging

import typer
import yaml
import pandas as pd

from pathlib import Path
from shutil import rmtree
from typing import Optional, List
from pydantic import BaseModel

from medcat.cat import CAT
from medcat.config import Config
from medcat.meta_cat import MetaCAT
from medcat.config_meta_cat import ConfigMetaCAT
from medcat.tokenizers.meta_cat_tokenizers import TokenizerWrapperBPE

from miade.model_builders import CDBBuilder
from miade.model_builders import VocabBuilder


log = logging.getLogger(__name__)

app = typer.Typer()


class CLI_Config(BaseModel):
    snomed_data_path: Optional[Path] = None
    fdb_data_path: Optional[Path] = None
    elg_data_path: Optional[Path] = None
    snomed_subset_path: Optional[Path] = None
    snomed_exclusions_path: Optional[Path] = None
    medcat_config_file: Optional[Path] = None
    training_data_path: Path
    output_dir: Path

    @classmethod
    def from_yaml_file(cls, config_filepath: Path):
        with config_filepath.open("r") as stream:
            config_dict = yaml.safe_load(stream)
            return cls(**config_dict)


@app.command()
def build_model_pack(
        config_file: Path,
        temp: Optional[Path] = typer.Argument(Path.cwd() / Path(".temp"))
):
    config = CLI_Config.from_yaml_file(config_file)

    # Load MedCAT configuration
    medcat_config = Config()
    if config.medcat_config_file:
        medcat_config.parse_config_file(str(config.medcat_config_file))

    cdb_builder = CDBBuilder(
        temp_dir=temp,
        snomed_data_path=config.snomed_data_path,
        fdb_data_path=config.fdb_data_path,
        elg_data_path=config.elg_data_path,
        snomed_subset_path=config.snomed_subset_path,
        snomed_exclusions_path=config.snomed_exclusions_path
    )

    cdb_builder.preprocess()
    cdb = cdb_builder.create_cdb()
    vocab_builder = VocabBuilder()

    with open(
            config.training_data_path, "r", encoding="utf-8"
    ) as training_data:
        training_data_list = [line.strip() for line in training_data]

    vocab = vocab_builder.create_new_vocab(
        training_data_list=training_data_list,
        cdb=cdb,
        config=medcat_config,
        output_dir=config.output_dir,
    )

    cat = CAT(cdb=cdb, config=cdb.config, vocab=vocab)
    cat.create_model_pack(str(config.output_dir))


@app.command()
def train(model: Path, data: Path,
          checkpoint: int = 5000,
          train_partial: Optional[int] = None,
          description: str = None,
          output: Optional[Path] = typer.Argument(Path.cwd())):
    if data.suffix == ".csv":
        log.info(f"Loading csv file {data}...")
        df = pd.read_csv(data)
        training_data = df.text.to_list()
        if train_partial:
            log.info(f"Partial training {train_partial} documents")
            training_data = training_data[:train_partial]
    else:
        with data.open('r') as d:
            training_data = [line.strip() for line in d]
    log.info("Training data length: ", len(training_data))

    cat = CAT.load_model_pack(str(model))
    if checkpoint:
        cat.config.general["checkpoint"]["steps"] = checkpoint
        cat.config.general["checkpoint"]["output_dir"] = os.path.join(Path.cwd(), "checkpoints")

    cat.train(training_data)

    if description is None:
        description = f"MiADE unsupervised trained model trained on text dataset {data.stem}"
    cat.config.version["description"] = description

    cat.create_model_pack(str(output))


@app.command()
def train_supervised(model: Path, annotations_path: Path,
                     nepochs: int = 1,
                     use_filters: bool = False,
                     print_stats: bool = True,
                     train_from_false_positives: bool = True,
                     is_resumed:bool = False,
                     description: str = None,
                     output: Optional[Path] = typer.Argument(Path.cwd())):
    cat = CAT.load_model_pack(str(model))

    fp, fn, tp, p, r, f1, cui_counts, examples = cat.train_supervised(data_path=str(annotations_path),
                                                                      nepochs=nepochs,
                                                                      use_filters=use_filters,
                                                                      print_stats=print_stats,
                                                                      train_from_false_positives=train_from_false_positives,
                                                                      is_resumed=is_resumed)

    # populate the description field in versioning
    if description is None:
        description = f"MiADE supervised trained model with annotations file {annotations_path.stem}"
    cat.config.version["description"] = description

    cat.create_model_pack(str(output))

    # dump the training stats into a json file for reference(they are very long)
    model_id = cat.config.version["id"]
    training_stats = {"fp": fp,
                      "fn": fn,
                      "tp": tp,
                      "p": p,
                      "r": r,
                      "f1": f1,
                      "cui_counts": cui_counts}

    # version without training text
    with open(str(output) + f"problems_model_supervised_training_stats_without_text_{model_id}.json", 'w') as f:
        json.dump(training_stats, f)

    training_stats["examples"] = examples
    # version with training text
    with open(str(output) + f"problems_model_supervised_training_stats_with_text_{model_id}.json", 'w') as f:
        json.dump(training_stats, f)


def train_metacat(model_path: Path, annotation_path: Path,
                  cntx_left: int = 20,
                  cntx_right: int = 15,
                  description: str = None):
    mc = MetaCAT.load(str(model_path))

    if description is None:
        description = f"MiADE meta-annotations model {model_path.stem} trained on {annotation_path.stem}"

    mc.config.general["description"] = description
    mc.config.general["category_name"] = model_path.stem.split("_")[-1]  # meta folder name should be e.g. meta_presence
    mc.config.general["cntx_left"] = cntx_left
    mc.config.general["cntx_right"] = cntx_right

    report = mc.train(json_path=str(annotation_path), save_dir_path=str(model_path))
    training_stats = {mc.config.general["category_name"]: report}

    with open(str(model_path) + "training_report.json", 'w') as f:
        json.dump(training_stats, f)


def add_metacat_models(model: Path, meta_cats_path: List[Path],
                       description: str = None,
                       output: Optional[Path] = typer.Argument(Path.cwd())):
    cat = CAT.load_model_pack(str(model))

    meta_cats = []
    categories = []
    stats = []
    for metacat in meta_cats_path:
        mc = MetaCAT.load(str(metacat))
        meta_cats.append(mc)
        categories.append(mc.config.general["category_name"])

        with open(str(metacat) + "training_report.json") as f:
            report = json.load(f)
        stats.append(report)

    cat_w_meta = CAT(cdb=cat.cdb, vocab=cat.vocab, config=cat.config, meta_cats=meta_cats)

    if description is None:
        description = cat.config.version["description"] + " Packaged with meta models " + ", ".join(categories)
    cat.config.version["description"] = description
    for category in categories:
        cat.config.version["performance"]["meta"][category] = stats[category]

    save_name = model.stem.rsplit("_", 1)[0] + "w_meta"
    cat_w_meta.create_model_pack(str(output), save_name)


def rename_model_pack(model: Path, new_name: str,
                      description: Optional[str] = None,
                      location: str = None,
                      ontology: str = None,
                      performance: str = None,
                      output: Optional[Path] = typer.Argument(Path.cwd())):
    cat = CAT.load_model_pack(str(model))

    cat.config.version["description"] = description
    cat.config.version["location"] = location
    cat.config.version["ontology"] = ontology
    cat.config.version["performance"] = performance

    cat.create_model_pack(str(output), new_name)

    # remove old model
    os.remove(str(model) + ".zip")
    rmtree(model)


if __name__ == "__main__":
    app()
